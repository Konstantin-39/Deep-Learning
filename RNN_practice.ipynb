{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекуррентные нейросети\n",
    "\n",
    "Построим простейшую нейросеть для посимвольной генерации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # для работы с данными\n",
    "import time  # для оценки времени выполнения\n",
    "import torch  # для работы с нейронными сетями\n",
    "from torch import nn  # для создания слоев нейронной сети\n",
    "\n",
    "# Определяем устройство (GPU или CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Будем работать с датасетом реплик из Симпсонов. Нам нужно извлечь предобработанные тексты и закодировать их числами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lazar\\AppData\\Local\\Temp\\ipykernel_132\\3859997088.py:2: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('simpsons_script_lines.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9549</td>\n",
       "      <td>32</td>\n",
       "      <td>209</td>\n",
       "      <td>Miss Hoover: No, actually, it was a little of ...</td>\n",
       "      <td>848000</td>\n",
       "      <td>True</td>\n",
       "      <td>464.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9550</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9551</td>\n",
       "      <td>32</td>\n",
       "      <td>211</td>\n",
       "      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>464.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9552</td>\n",
       "      <td>32</td>\n",
       "      <td>212</td>\n",
       "      <td>Lisa Simpson: That life is worth living.</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>That life is worth living.</td>\n",
       "      <td>that life is worth living</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9553</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  episode_id  number  \\\n",
       "0  9549          32     209   \n",
       "1  9550          32     210   \n",
       "2  9551          32     211   \n",
       "3  9552          32     212   \n",
       "4  9553          32     213   \n",
       "\n",
       "                                            raw_text timestamp_in_ms  \\\n",
       "0  Miss Hoover: No, actually, it was a little of ...          848000   \n",
       "1  Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n",
       "2  Miss Hoover: I don't know. Although I'd sure l...          856000   \n",
       "3           Lisa Simpson: That life is worth living.          864000   \n",
       "4  Edna Krabappel-Flanders: The polls will be ope...          864000   \n",
       "\n",
       "  speaking_line character_id  location_id       raw_character_text  \\\n",
       "0          True        464.0          3.0              Miss Hoover   \n",
       "1          True          9.0          3.0             Lisa Simpson   \n",
       "2          True        464.0          3.0              Miss Hoover   \n",
       "3          True          9.0          3.0             Lisa Simpson   \n",
       "4          True         40.0          3.0  Edna Krabappel-Flanders   \n",
       "\n",
       "               raw_location_text  \\\n",
       "0  Springfield Elementary School   \n",
       "1  Springfield Elementary School   \n",
       "2  Springfield Elementary School   \n",
       "3  Springfield Elementary School   \n",
       "4  Springfield Elementary School   \n",
       "\n",
       "                                        spoken_words  \\\n",
       "0  No, actually, it was a little of both. Sometim...   \n",
       "1                             Where's Mr. Bergstrom?   \n",
       "2  I don't know. Although I'd sure like to talk t...   \n",
       "3                         That life is worth living.   \n",
       "4  The polls will be open from now until the end ...   \n",
       "\n",
       "                                     normalized_text word_count  \n",
       "0  no actually it was a little of both sometimes ...         31  \n",
       "1                                wheres mr bergstrom          3  \n",
       "2  i dont know although id sure like to talk to h...         22  \n",
       "3                          that life is worth living          5  \n",
       "4  the polls will be open from now until the end ...         33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('simpsons_script_lines.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no actually it was a little of both sometimes when a disease is in all the magazines and all the news shows its only natural that you think you have it',\n",
       " 'wheres mr bergstrom',\n",
       " 'i dont know although id sure like to talk to him he didnt touch my lesson plan what did he teach you',\n",
       " 'that life is worth living',\n",
       " 'the polls will be open from now until the end of recess now just in case any of you have decided to put any thought into this well have our final statements martin',\n",
       " 'i dont think theres anything left to say',\n",
       " 'bart',\n",
       " 'victory party under the slide',\n",
       " nan,\n",
       " 'mr bergstrom mr bergstrom']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразуем тексты в список\n",
    "phrases = df['normalized_text'].tolist()  # колонка с предобработанными текстами\n",
    "phrases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем каждый текст в список символов\n",
    "text = [[char for char in phrase] for phrase in phrases if isinstance(phrase, str)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаём массив с данными\n",
    "\n",
    "Нужно\n",
    "\n",
    "1. Разбить данные на токены (у нас символы)\n",
    "2. Закодировать числами\n",
    "3. Превратить в эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем допустимые символы\n",
    "CHARS = set('abcdefghijklmnopqrstuvwxyz ')  # все символы, которые мы хотим использовать для кодировки\n",
    "INDEX_TO_CHAR = ['none'] + list(CHARS)  # все неизвестные символы будут получать тег 'none'\n",
    "CHAR_TO_INDEX = {char: idx for idx, char in enumerate(INDEX_TO_CHAR)}  # словарь для преобразования символа в индекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(INDEX_TO_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ограничиваем максимальную длину текста\n",
    "MAX_LEN = 50\n",
    "\n",
    "# Создаем тензор для хранения индексов символов\n",
    "X = torch.zeros((len(text), MAX_LEN), dtype=int).to(device)  # перемещаем на устройство\n",
    "\n",
    "# Заполняем тензор индексами символов\n",
    "for i, phrase in enumerate(text):\n",
    "    for j, char in enumerate(phrase):\n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(char, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 16, 25, 19, 10,  7, 11, 19, 24, 24, 15, 25,  6,  7, 25,  5, 19,  4,\n",
       "         25, 19, 25, 24,  6,  7,  7, 24, 20, 25, 16, 27, 25, 13, 16,  7, 21, 25,\n",
       "          4, 16, 18, 20,  7,  6, 18, 20,  4, 25,  5, 21, 20,  8],\n",
       "        [ 5, 21, 20,  3, 20,  4, 25, 18,  3, 25, 13, 20,  3, 26,  4,  7,  3, 16,\n",
       "         18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 6, 25,  2, 16,  8,  7, 25, 12,  8, 16,  5, 25, 19, 24,  7, 21, 16, 11,\n",
       "         26, 21, 25,  6,  2, 25,  4, 11,  3, 20, 25, 24,  6, 12, 20, 25,  7, 16,\n",
       "         25,  7, 19, 24, 12, 25,  7, 16, 25, 21,  6, 18, 25, 21],\n",
       "        [ 7, 21, 19,  7, 25, 24,  6, 27, 20, 25,  6,  4, 25,  5, 16,  3,  7, 21,\n",
       "         25, 24,  6, 22,  6,  8, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 7, 21, 20, 25,  9, 16, 24, 24,  4, 25,  5,  6, 24, 24, 25, 13, 20, 25,\n",
       "         16,  9, 20,  8, 25, 27,  3, 16, 18, 25,  8, 16,  5, 25, 11,  8,  7,  6,\n",
       "         24, 25,  7, 21, 20, 25, 20,  8,  2, 25, 16, 27, 25,  3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding и RNN ячейки\n",
    "\n",
    "Каждому токену мы хотим сопоставить не просто число, но вектор. Поэтому вектор текста нам нужно умножить на матрицу эмбеддингов, которая тоже будет учиться в процессе обучения нейросети. Для создания такой матрицы нам нужен слой `nn.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 50])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 50, 28])\n"
     ]
    }
   ],
   "source": [
    "# Создаем слой для эмбеддингов\n",
    "embeddings = nn.Embedding(len(INDEX_TO_CHAR), 28).to(device)  # перемещаем на устройство\n",
    "t = embeddings(X[0:5])  # Пример эмбеддинга для первых 5 фраз\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 50, 28]), torch.Size([5, 50]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, X[0:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 50, 128]) torch.Size([1, 5, 128])\n"
     ]
    }
   ],
   "source": [
    "# Создаем RNN слой\n",
    "rnn = nn.RNN(28, 128, batch_first=True).to(device)  # перемещаем на устройство\n",
    "output, hidden_state = rnn(t)\n",
    "\n",
    "# Размеры выходных данных\n",
    "print(output.shape, hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация сети с RNN\n",
    "3 слоя:\n",
    "1. Embeding (30)\n",
    "2. RNN (hidden_dim=128)\n",
    "3. Полносвязный слой для предсказания буквы (28, то есть размер словаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем архитектуру нейронной сети\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(INDEX_TO_CHAR), 30).to(device)  # слой эмбеддинга\n",
    "        self.rnn = nn.RNN(30, 128).to(device)  # RNN слой\n",
    "        self.out = nn.Linear(128, len(INDEX_TO_CHAR)).to(device)  # выходной слой\n",
    "\n",
    "    def forward(self, sentences, state=None):\n",
    "        x = self.embedding(sentences)  # преобразуем индексы в эмбеддинги\n",
    "        x, hidden_state = self.rnn(x)  # пропускаем через RNN\n",
    "        return self.out(x)  # возвращаем выходной слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель, функцию потерь и оптимизатор\n",
    "model = Network().to(device)  # перемещаем модель на устройство\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # функция потерь для многоклассовой классификации\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 57.995, Train loss: 1.831\n",
      "Epoch 1. Time: 54.678, Train loss: 1.729\n",
      "Epoch 2. Time: 58.122, Train loss: 1.712\n",
      "Epoch 3. Time: 61.115, Train loss: 1.703\n",
      "Epoch 4. Time: 59.554, Train loss: 1.697\n",
      "Epoch 5. Time: 56.450, Train loss: 1.692\n",
      "Epoch 6. Time: 58.767, Train loss: 1.685\n",
      "Epoch 7. Time: 54.431, Train loss: 1.681\n",
      "Epoch 8. Time: 56.086, Train loss: 1.678\n",
      "Epoch 9. Time: 61.733, Train loss: 1.675\n",
      "Epoch 10. Time: 56.695, Train loss: 1.672\n",
      "Epoch 11. Time: 54.101, Train loss: 1.670\n",
      "Epoch 12. Time: 54.102, Train loss: 1.668\n",
      "Epoch 13. Time: 53.346, Train loss: 1.667\n",
      "Epoch 14. Time: 52.265, Train loss: 1.666\n",
      "Epoch 15. Time: 58.017, Train loss: 1.665\n",
      "Epoch 16. Time: 66.032, Train loss: 1.664\n",
      "Epoch 17. Time: 82.395, Train loss: 1.663\n",
      "Epoch 18. Time: 72.687, Train loss: 1.662\n",
      "Epoch 19. Time: 54.346, Train loss: 1.662\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "for epoch in range(20):\n",
    "    start = time.time()\n",
    "    train_loss = 0.0\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        # Берем батч из 100 элементов\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1].to(device)  # входные данные\n",
    "        Y_batch = batch[:, 1:].flatten().to(device)  # целевые данные\n",
    "\n",
    "        optimizer.zero_grad()  # обнуляем градиенты\n",
    "        answers = model(X_batch)  # получаем предсказания\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))  # изменяем форму для функции потерь\n",
    "        loss = criterion(answers, Y_batch)  # вычисляем потери\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()  # обратное распространение ошибки\n",
    "        optimizer.step()  # обновляем веса\n",
    "        train_passed += 1\n",
    "\n",
    "    # Выводим статистику по эпохе\n",
    "    print(f\"Epoch {epoch}. Time: {time.time() - start:.3f}, Train loss: {train_loss / train_passed:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация\n",
    "\n",
    "\n",
    "- Сначала отправлем в модель буквы из предложения (прогревая состояние)\n",
    "- Затем берём самую вероятную букву и добавляем её в предложение\n",
    "- Повторяем пока не получим none (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR_TO_INDEX['none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для генерации предложения\n",
    "def generate_sentence(word):\n",
    "    model.eval()  # переключаем модель в режим оценки\n",
    "    with torch.no_grad():  # отключаем вычисление градиентов\n",
    "        sentence = list(word)\n",
    "        sentence = [CHAR_TO_INDEX.get(char, 0) for char in sentence]  # преобразуем символы в индексы\n",
    "        sentence_tensor = torch.tensor(sentence).unsqueeze(0).to(device)  # перемещаем на устройство\n",
    "        answers = model(sentence_tensor)  # получаем предсказания\n",
    "        _, indices = answers.topk(1)  # выбираем наиболее вероятные символы\n",
    "        return ''.join([INDEX_TO_CHAR[idx.item()] for idx in indices.flatten()])  # преобразуем индексы обратно в символы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentence: e ll te el \n"
     ]
    }
   ],
   "source": [
    "# Пример работы\n",
    "test_text = \"hello world\"\n",
    "print(f\"Generated sentence: {generate_sentence(test_text)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
