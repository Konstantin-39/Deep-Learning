{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Задание\n",
        "1. Скачать [датасет](https://www.manythings.org/anki/rus-eng.zip) англо-русскую пару фраз\n",
        "2. Обучим seq2seq, оценим качество\n",
        "3. Добавим +1 рекуррентный слой в encoder и decoder\n",
        "4. Обучим модель LSTM и оценим качество модели \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Загрузим данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-YlRH3mQM9tf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MIEGXF8oM9tt"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "colab_type": "code",
        "id": "8UKlPFcBNZl5",
        "outputId": "c4eb79b7-0097-427e-f25c-a5f5e9473449"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2025-02-09 17:52:49--  https://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16305013 (16M) [application/zip]\n",
            "Saving to: 'rus-eng.zip'\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0%  157K 1m41s\n",
            "    50K .......... .......... .......... .......... ..........  0%  313K 76s\n",
            "   100K .......... .......... .......... .......... ..........  0% 12,7M 51s\n",
            "   150K .......... .......... .......... .......... ..........  1%  314K 50s\n",
            "   200K .......... .......... .......... .......... ..........  1%  314K 50s\n",
            "   250K .......... .......... .......... .......... ..........  1% 13,5M 42s\n",
            "   300K .......... .......... .......... .......... ..........  2%  309K 43s\n",
            "   350K .......... .......... .......... .......... ..........  2%  316K 44s\n",
            "   400K .......... .......... .......... .......... ..........  2%  297K 44s\n",
            "   450K .......... .......... .......... .......... ..........  3% 8,32M 40s\n",
            "   500K .......... .......... .......... .......... ..........  3%  330K 41s\n",
            "   550K .......... .......... .......... .......... ..........  3%  323K 41s\n",
            "   600K .......... .......... .......... .......... ..........  4%  313K 41s\n",
            "   650K .......... .......... .......... .......... ..........  4% 6,18M 39s\n",
            "   700K .......... .......... .......... .......... ..........  4%  157K 42s\n",
            "   750K .......... .......... .......... .......... ..........  5% 22,1M 40s\n",
            "   800K .......... .......... .......... .......... ..........  5%  322K 40s\n",
            "   850K .......... .......... .......... .......... ..........  5%  312K 40s\n",
            "   900K .......... .......... .......... .......... ..........  5%  314K 40s\n",
            "   950K .......... .......... .......... .......... ..........  6%  313K 41s\n",
            "  1000K .......... .......... .......... .......... ..........  6%  317K 41s\n",
            "  1050K .......... .......... .......... .......... ..........  6% 3,72M 39s\n",
            "  1100K .......... .......... .......... .......... ..........  7%  317K 39s\n",
            "  1150K .......... .......... .......... .......... ..........  7%  317K 39s\n",
            "  1200K .......... .......... .......... .......... ..........  7%  314K 40s\n",
            "  1250K .......... .......... .......... .......... ..........  8%  319K 40s\n",
            "  1300K .......... .......... .......... .......... ..........  8%  324K 40s\n",
            "  1350K .......... .......... .......... .......... ..........  8%  156K 42s\n",
            "  1400K .......... .......... .......... .......... ..........  9% 12,6M 40s\n",
            "  1450K .......... .......... .......... .......... ..........  9%  307K 40s\n",
            "  1500K .......... .......... .......... .......... ..........  9%  314K 40s\n",
            "  1550K .......... .......... .......... .......... .......... 10%  313K 40s\n",
            "  1600K .......... .......... .......... .......... .......... 10%  305K 40s\n",
            "  1650K .......... .......... .......... .......... .......... 10%  317K 40s\n",
            "  1700K .......... .......... .......... .......... .......... 10%  311K 40s\n",
            "  1750K .......... .......... .......... .......... .......... 11%  314K 40s\n",
            "  1800K .......... .......... .......... .......... .......... 11%  320K 40s\n",
            "  1850K .......... .......... .......... .......... .......... 11%  311K 40s\n",
            "  1900K .......... .......... .......... .......... .......... 12% 3,58M 39s\n",
            "  1950K .......... .......... .......... .......... .......... 12%  323K 39s\n",
            "  2000K .......... .......... .......... .......... .......... 12%  314K 39s\n",
            "  2050K .......... .......... .......... .......... .......... 13%  157K 40s\n",
            "  2100K .......... .......... .......... .......... .......... 13% 12,6M 39s\n",
            "  2150K .......... .......... .......... .......... .......... 13%  309K 39s\n",
            "  2200K .......... .......... .......... .......... .......... 14%  311K 39s\n",
            "  2250K .......... .......... .......... .......... .......... 14%  313K 39s\n",
            "  2300K .......... .......... .......... .......... .......... 14%  311K 39s\n",
            "  2350K .......... .......... .......... .......... .......... 15%  312K 39s\n",
            "  2400K .......... .......... .......... .......... .......... 15%  313K 39s\n",
            "  2450K .......... .......... .......... .......... .......... 15%  308K 39s\n",
            "  2500K .......... .......... .......... .......... .......... 16%  316K 39s\n",
            "  2550K .......... .......... .......... .......... .......... 16%  318K 39s\n",
            "  2600K .......... .......... .......... .......... .......... 16%  313K 39s\n",
            "  2650K .......... .......... .......... .......... .......... 16%  304K 39s\n",
            "  2700K .......... .......... .......... .......... .......... 17%  322K 38s\n",
            "  2750K .......... .......... .......... .......... .......... 17%  307K 38s\n",
            "  2800K .......... .......... .......... .......... .......... 17%  313K 38s\n",
            "  2850K .......... .......... .......... .......... .......... 18%  245K 38s\n",
            "  2900K .......... .......... .......... .......... .......... 18%  312K 38s\n",
            "  2950K .......... .......... .......... .......... .......... 18%  115K 39s\n",
            "  3000K .......... .......... .......... .......... .......... 19% 21,5M 39s\n",
            "  3050K .......... .......... .......... .......... .......... 19%  157K 39s\n",
            "  3100K .......... .......... .......... .......... .......... 19%  308K 39s\n",
            "  3150K .......... .......... .......... .......... .......... 20%  309K 39s\n",
            "  3200K .......... .......... .......... .......... .......... 20%  202K 39s\n",
            "  3250K .......... .......... .......... .......... .......... 20%  312K 39s\n",
            "  3300K .......... .......... .......... .......... .......... 21%  310K 39s\n",
            "  3350K .......... .......... .......... .......... .......... 21%  217K 39s\n",
            "  3400K .......... .......... .......... .......... .......... 21%  312K 39s\n",
            "  3450K .......... .......... .......... .......... .......... 21%  309K 39s\n",
            "  3500K .......... .......... .......... .......... .......... 22%  311K 39s\n",
            "  3550K .......... .......... .......... .......... .......... 22%  313K 38s\n",
            "  3600K .......... .......... .......... .......... .......... 22%  310K 38s\n",
            "  3650K .......... .......... .......... .......... .......... 23%  310K 38s\n",
            "  3700K .......... .......... .......... .......... .......... 23%  228K 38s\n",
            "  3750K .......... .......... .......... .......... .......... 23%  314K 38s\n",
            "  3800K .......... .......... .......... .......... .......... 24%  188K 38s\n",
            "  3850K .......... .......... .......... .......... .......... 24%  235K 38s\n",
            "  3900K .......... .......... .......... .......... .......... 24%  312K 38s\n",
            "  3950K .......... .......... .......... .......... .......... 25%  239K 38s\n",
            "  4000K .......... .......... .......... .......... .......... 25%  219K 38s\n",
            "  4050K .......... .......... .......... .......... .......... 25%  312K 38s\n",
            "  4100K .......... .......... .......... .......... .......... 26%  313K 38s\n",
            "  4150K .......... .......... .......... .......... .......... 26%  312K 38s\n",
            "  4200K .......... .......... .......... .......... .......... 26%  311K 37s\n",
            "  4250K .......... .......... .......... .......... .......... 27%  312K 37s\n",
            "  4300K .......... .......... .......... .......... .......... 27%  313K 37s\n",
            "  4350K .......... .......... .......... .......... .......... 27%  247K 37s\n",
            "  4400K .......... .......... .......... .......... .......... 27%  407K 37s\n",
            "  4450K .......... .......... .......... .......... .......... 28%  249K 37s\n",
            "  4500K .......... .......... .......... .......... .......... 28%  318K 37s\n",
            "  4550K .......... .......... .......... .......... .......... 28%  313K 36s\n",
            "  4600K .......... .......... .......... .......... .......... 29%  302K 36s\n",
            "  4650K .......... .......... .......... .......... .......... 29%  314K 36s\n",
            "  4700K .......... .......... .......... .......... .......... 29%  312K 36s\n",
            "  4750K .......... .......... .......... .......... .......... 30%  314K 36s\n",
            "  4800K .......... .......... .......... .......... .......... 30%  314K 36s\n",
            "  4850K .......... .......... .......... .......... .......... 30%  172K 36s\n",
            "  4900K .......... .......... .......... .......... .......... 31%  155K 36s\n",
            "  4950K .......... .......... .......... .......... .......... 31%  140K 36s\n",
            "  5000K .......... .......... .......... .......... .......... 31%  113K 37s\n",
            "  5050K .......... .......... .......... .......... .......... 32%  156K 37s\n",
            "  5100K .......... .......... .......... .......... .......... 32%  104K 37s\n",
            "  5150K .......... .......... .......... .......... .......... 32%  112K 38s\n",
            "  5200K .......... .......... .......... .......... .......... 32%  140K 38s\n",
            "  5250K .......... .......... .......... .......... .......... 33%  156K 38s\n",
            "  5300K .......... .......... .......... .......... .......... 33%  155K 38s\n",
            "  5350K .......... .......... .......... .......... .......... 33%  156K 38s\n",
            "  5400K .......... .......... .......... .......... .......... 34%  156K 38s\n",
            "  5450K .......... .......... .......... .......... .......... 34%  240K 38s\n",
            "  5500K .......... .......... .......... .......... .......... 34%  180K 38s\n",
            "  5550K .......... .......... .......... .......... .......... 35%  246K 38s\n",
            "  5600K .......... .......... .......... .......... .......... 35%  178K 38s\n",
            "  5650K .......... .......... .......... .......... .......... 35%  245K 38s\n",
            "  5700K .......... .......... .......... .......... .......... 36%  180K 38s\n",
            "  5750K .......... .......... .......... .......... .......... 36%  248K 38s\n",
            "  5800K .......... .......... .......... .......... .......... 36%  183K 38s\n",
            "  5850K .......... .......... .......... .......... .......... 37%  302K 37s\n",
            "  5900K .......... .......... .......... .......... .......... 37%  249K 37s\n",
            "  5950K .......... .......... .......... .......... .......... 37%  311K 37s\n",
            "  6000K .......... .......... .......... .......... .......... 37%  312K 37s\n",
            "  6050K .......... .......... .......... .......... .......... 38%  312K 37s\n",
            "  6100K .......... .......... .......... .......... .......... 38%  314K 36s\n",
            "  6150K .......... .......... .......... .......... .......... 38%  437K 36s\n",
            "  6200K .......... .......... .......... .......... .......... 39%  931K 36s\n",
            "  6250K .......... .......... .......... .......... .......... 39%  324K 35s\n",
            "  6300K .......... .......... .......... .......... .......... 39%  434K 35s\n",
            "  6350K .......... .......... .......... .......... .......... 40%  316K 35s\n",
            "  6400K .......... .......... .......... .......... .......... 40% 1,05M 35s\n",
            "  6450K .......... .......... .......... .......... .......... 40%  433K 34s\n",
            "  6500K .......... .......... .......... .......... .......... 41% 1,04M 34s\n",
            "  6550K .......... .......... .......... .......... .......... 41%  428K 34s\n",
            "  6600K .......... .......... .......... .......... .......... 41% 1,09M 33s\n",
            "  6650K .......... .......... .......... .......... .......... 42%  428K 33s\n",
            "  6700K .......... .......... .......... .......... .......... 42% 1,11M 33s\n",
            "  6750K .......... .......... .......... .......... .......... 42%  434K 32s\n",
            "  6800K .......... .......... .......... .......... .......... 43% 1,14M 32s\n",
            "  6850K .......... .......... .......... .......... .......... 43%  427K 32s\n",
            "  6900K .......... .......... .......... .......... .......... 43% 1,25M 31s\n",
            "  6950K .......... .......... .......... .......... .......... 43% 5,97M 31s\n",
            "  7000K .......... .......... .......... .......... .......... 44%  433K 31s\n",
            "  7050K .......... .......... .......... .......... .......... 44% 1,24M 30s\n",
            "  7100K .......... .......... .......... .......... .......... 44%  425K 30s\n",
            "  7150K .......... .......... .......... .......... .......... 45% 1,28M 30s\n",
            "  7200K .......... .......... .......... .......... .......... 45% 5,25M 29s\n",
            "  7250K .......... .......... .......... .......... .......... 45%  439K 29s\n",
            "  7300K .......... .......... .......... .......... .......... 46% 1,28M 29s\n",
            "  7350K .......... .......... .......... .......... .......... 46% 6,04M 29s\n",
            "  7400K .......... .......... .......... .......... .......... 46%  440K 28s\n",
            "  7450K .......... .......... .......... .......... .......... 47% 1,22M 28s\n",
            "  7500K .......... .......... .......... .......... .......... 47% 10,4M 28s\n",
            "  7550K .......... .......... .......... .......... .......... 47%  432K 27s\n",
            "  7600K .......... .......... .......... .......... .......... 48% 1,38M 27s\n",
            "  7650K .......... .......... .......... .......... .......... 48% 6,08M 27s\n",
            "  7700K .......... .......... .......... .......... .......... 48%  438K 27s\n",
            "  7750K .......... .......... .......... .......... .......... 48% 2,61M 26s\n",
            "  7800K .......... .......... .......... .......... .......... 49%  272K 26s\n",
            "  7850K .......... .......... .......... .......... .......... 49% 37,2M 26s\n",
            "  7900K .......... .......... .......... .......... .......... 49% 35,1M 25s\n",
            "  7950K .......... .......... .......... .......... .......... 50% 31,5M 25s\n",
            "  8000K .......... .......... .......... .......... .......... 50% 20,3M 25s\n",
            "  8050K .......... .......... .......... .......... .......... 50%  425K 25s\n",
            "  8100K .......... .......... .......... .......... .......... 51% 1,28M 24s\n",
            "  8150K .......... .......... .......... .......... .......... 51% 5,07M 24s\n",
            "  8200K .......... .......... .......... .......... .......... 51%  394K 24s\n",
            "  8250K .......... .......... .......... .......... .......... 52% 1,76M 24s\n",
            "  8300K .......... .......... .......... .......... .......... 52%  306K 23s\n",
            "  8350K .......... .......... .......... .......... .......... 52% 11,5M 23s\n",
            "  8400K .......... .......... .......... .......... .......... 53% 11,3M 23s\n",
            "  8450K .......... .......... .......... .......... .......... 53%  416K 23s\n",
            "  8500K .......... .......... .......... .......... .......... 53% 1,57M 22s\n",
            "  8550K .......... .......... .......... .......... .......... 54%  422K 22s\n",
            "  8600K .......... .......... .......... .......... .......... 54% 1,16M 22s\n",
            "  8650K .......... .......... .......... .......... .......... 54%  424K 22s\n",
            "  8700K .......... .......... .......... .......... .......... 54% 1,16M 22s\n",
            "  8750K .......... .......... .......... .......... .......... 55%  428K 21s\n",
            "  8800K .......... .......... .......... .......... .......... 55% 1,23M 21s\n",
            "  8850K .......... .......... .......... .......... .......... 55%  414K 21s\n",
            "  8900K .......... .......... .......... .......... .......... 56% 1,59M 21s\n",
            "  8950K .......... .......... .......... .......... .......... 56% 2,98M 21s\n",
            "  9000K .......... .......... .......... .......... .......... 56%  355K 20s\n",
            "  9050K .......... .......... .......... .......... .......... 57% 2,83M 20s\n",
            "  9100K .......... .......... .......... .......... .......... 57%  381K 20s\n",
            "  9150K .......... .......... .......... .......... .......... 57% 1,73M 20s\n",
            "  9200K .......... .......... .......... .......... .......... 58%  426K 20s\n",
            "  9250K .......... .......... .......... .......... .......... 58%  950K 19s\n",
            "  9300K .......... .......... .......... .......... .......... 58%  490K 19s\n",
            "  9350K .......... .......... .......... .......... .......... 59% 1,27M 19s\n",
            "  9400K .......... .......... .......... .......... .......... 59%  174K 19s\n",
            "  9450K .......... .......... .......... .......... .......... 59% 3,46M 19s\n",
            "  9500K .......... .......... .......... .......... .......... 59% 12,1M 18s\n",
            "  9550K .......... .......... .......... .......... .......... 60% 1,13M 18s\n",
            "  9600K .......... .......... .......... .......... .......... 60%  385K 18s\n",
            "  9650K .......... .......... .......... .......... .......... 60%  389K 18s\n",
            "  9700K .......... .......... .......... .......... .......... 61%  950K 18s\n",
            "  9750K .......... .......... .......... .......... .......... 61%  406K 18s\n",
            "  9800K .......... .......... .......... .......... .......... 61% 1,16M 17s\n",
            "  9850K .......... .......... .......... .......... .......... 62%  397K 17s\n",
            "  9900K .......... .......... .......... .......... .......... 62% 1,02M 17s\n",
            "  9950K .......... .......... .......... .......... .......... 62%  409K 17s\n",
            " 10000K .......... .......... .......... .......... .......... 63%  174K 17s\n",
            " 10050K .......... .......... .......... .......... .......... 63% 1,49M 17s\n",
            " 10100K .......... .......... .......... .......... .......... 63% 15,2M 16s\n",
            " 10150K .......... .......... .......... .......... .......... 64%  368K 16s\n",
            " 10200K .......... .......... .......... .......... .......... 64%  345K 16s\n",
            " 10250K .......... .......... .......... .......... .......... 64%  575K 16s\n",
            " 10300K .......... .......... .......... .......... .......... 65%  455K 16s\n",
            " 10350K .......... .......... .......... .......... .......... 65%  380K 16s\n",
            " 10400K .......... .......... .......... .......... .......... 65%  584K 15s\n",
            " 10450K .......... .......... .......... .......... .......... 65%  398K 15s\n",
            " 10500K .......... .......... .......... .......... .......... 66%  427K 15s\n",
            " 10550K .......... .......... .......... .......... .......... 66%  633K 15s\n",
            " 10600K .......... .......... .......... .......... .......... 66%  405K 15s\n",
            " 10650K .......... .......... .......... .......... .......... 67%  459K 15s\n",
            " 10700K .......... .......... .......... .......... .......... 67%  560K 14s\n",
            " 10750K .......... .......... .......... .......... .......... 67%  491K 14s\n",
            " 10800K .......... .......... .......... .......... .......... 68%  402K 14s\n",
            " 10850K .......... .......... .......... .......... .......... 68%  547K 14s\n",
            " 10900K .......... .......... .......... .......... .......... 68%  484K 14s\n",
            " 10950K .......... .......... .......... .......... .......... 69%  400K 14s\n",
            " 11000K .......... .......... .......... .......... .......... 69%  555K 14s\n",
            " 11050K .......... .......... .......... .......... .......... 69%  484K 13s\n",
            " 11100K .......... .......... .......... .......... .......... 70%  396K 13s\n",
            " 11150K .......... .......... .......... .......... .......... 70%  579K 13s\n",
            " 11200K .......... .......... .......... .......... .......... 70%  441K 13s\n",
            " 11250K .......... .......... .......... .......... .......... 70%  426K 13s\n",
            " 11300K .......... .......... .......... .......... .......... 71%  943K 13s\n",
            " 11350K .......... .......... .......... .......... .......... 71%  392K 12s\n",
            " 11400K .......... .......... .......... .......... .......... 71%  260K 12s\n",
            " 11450K .......... .......... .......... .......... .......... 72% 1,37M 12s\n",
            " 11500K .......... .......... .......... .......... .......... 72%  408K 12s\n",
            " 11550K .......... .......... .......... .......... .......... 72%  325K 12s\n",
            " 11600K .......... .......... .......... .......... .......... 73%  413K 12s\n",
            " 11650K .......... .......... .......... .......... .......... 73%  379K 12s\n",
            " 11700K .......... .......... .......... .......... .......... 73%  419K 11s\n",
            " 11750K .......... .......... .......... .......... .......... 74%  422K 11s\n",
            " 11800K .......... .......... .......... .......... .......... 74%  456K 11s\n",
            " 11850K .......... .......... .......... .......... .......... 74%  332K 11s\n",
            " 11900K .......... .......... .......... .......... .......... 75%  509K 11s\n",
            " 11950K .......... .......... .......... .......... .......... 75%  446K 11s\n",
            " 12000K .......... .......... .......... .......... .......... 75%  458K 11s\n",
            " 12050K .......... .......... .......... .......... .......... 75%  501K 10s\n",
            " 12100K .......... .......... .......... .......... .......... 76%  447K 10s\n",
            " 12150K .......... .......... .......... .......... .......... 76%  437K 10s\n",
            " 12200K .......... .......... .......... .......... .......... 76%  359K 10s\n",
            " 12250K .......... .......... .......... .......... .......... 77%  768K 10s\n",
            " 12300K .......... .......... .......... .......... .......... 77%  466K 10s\n",
            " 12350K .......... .......... .......... .......... .......... 77%  501K 10s\n",
            " 12400K .......... .......... .......... .......... .......... 78%  460K 9s\n",
            " 12450K .......... .......... .......... .......... .......... 78%  425K 9s\n",
            " 12500K .......... .......... .......... .......... .......... 78%  532K 9s\n",
            " 12550K .......... .......... .......... .......... .......... 79%  610K 9s\n",
            " 12600K .......... .......... .......... .......... .......... 79%  375K 9s\n",
            " 12650K .......... .......... .......... .......... .......... 79%  766K 9s\n",
            " 12700K .......... .......... .......... .......... .......... 80%  341K 9s\n",
            " 12750K .......... .......... .......... .......... .......... 80%  463K 8s\n",
            " 12800K .......... .......... .......... .......... .......... 80%  810K 8s\n",
            " 12850K .......... .......... .......... .......... .......... 81%  457K 8s\n",
            " 12900K .......... .......... .......... .......... .......... 81%  341K 8s\n",
            " 12950K .......... .......... .......... .......... .......... 81%  793K 8s\n",
            " 13000K .......... .......... .......... .......... .......... 81%  462K 8s\n",
            " 13050K .......... .......... .......... .......... .......... 82%  517K 8s\n",
            " 13100K .......... .......... .......... .......... .......... 82%  455K 7s\n",
            " 13150K .......... .......... .......... .......... .......... 82%  477K 7s\n",
            " 13200K .......... .......... .......... .......... .......... 83%  475K 7s\n",
            " 13250K .......... .......... .......... .......... .......... 83%  476K 7s\n",
            " 13300K .......... .......... .......... .......... .......... 83%  456K 7s\n",
            " 13350K .......... .......... .......... .......... .......... 84%  479K 7s\n",
            " 13400K .......... .......... .......... .......... .......... 84%  473K 7s\n",
            " 13450K .......... .......... .......... .......... .......... 84%  453K 6s\n",
            " 13500K .......... .......... .......... .......... .......... 85%  491K 6s\n",
            " 13550K .......... .......... .......... .......... .......... 85%  771K 6s\n",
            " 13600K .......... .......... .......... .......... .......... 85%  333K 6s\n",
            " 13650K .......... .......... .......... .......... .......... 86%  814K 6s\n",
            " 13700K .......... .......... .......... .......... .......... 86%  462K 6s\n",
            " 13750K .......... .......... .......... .......... .......... 86%  515K 6s\n",
            " 13800K .......... .......... .......... .......... .......... 86%  438K 6s\n",
            " 13850K .......... .......... .......... .......... .......... 87%  492K 5s\n",
            " 13900K .......... .......... .......... .......... .......... 87%  490K 5s\n",
            " 13950K .......... .......... .......... .......... .......... 87%  458K 5s\n",
            " 14000K .......... .......... .......... .......... .......... 88%  495K 5s\n",
            " 14050K .......... .......... .......... .......... .......... 88%  761K 5s\n",
            " 14100K .......... .......... .......... .......... .......... 88%  456K 5s\n",
            " 14150K .......... .......... .......... .......... .......... 89%  519K 5s\n",
            " 14200K .......... .......... .......... .......... .......... 89%  442K 4s\n",
            " 14250K .......... .......... .......... .......... .......... 89%  522K 4s\n",
            " 14300K .......... .......... .......... .......... .......... 90%  752K 4s\n",
            " 14350K .......... .......... .......... .......... .......... 90%  507K 4s\n",
            " 14400K .......... .......... .......... .......... .......... 90%  479K 4s\n",
            " 14450K .......... .......... .......... .......... .......... 91%  775K 4s\n",
            " 14500K .......... .......... .......... .......... .......... 91%  512K 4s\n",
            " 14550K .......... .......... .......... .......... .......... 91%  799K 3s\n",
            " 14600K .......... .......... .......... .......... .......... 92%  347K 3s\n",
            " 14650K .......... .......... .......... .......... .......... 92%  834K 3s\n",
            " 14700K .......... .......... .......... .......... .......... 92%  490K 3s\n",
            " 14750K .......... .......... .......... .......... .......... 92%  853K 3s\n",
            " 14800K .......... .......... .......... .......... .......... 93%  495K 3s\n",
            " 14850K .......... .......... .......... .......... .......... 93%  779K 3s\n",
            " 14900K .......... .......... .......... .......... .......... 93%  519K 3s\n",
            " 14950K .......... .......... .......... .......... .......... 94%  843K 2s\n",
            " 15000K .......... .......... .......... .......... .......... 94%  499K 2s\n",
            " 15050K .......... .......... .......... .......... .......... 94% 2,76M 2s\n",
            " 15100K .......... .......... .......... .......... .......... 95%  363K 2s\n",
            " 15150K .......... .......... .......... .......... .......... 95% 2,53M 2s\n",
            " 15200K .......... .......... .......... .......... .......... 95%  491K 2s\n",
            " 15250K .......... .......... .......... .......... .......... 96% 1005K 2s\n",
            " 15300K .......... .......... .......... .......... .......... 96%  845K 1s\n",
            " 15350K .......... .......... .......... .......... .......... 96%  521K 1s\n",
            " 15400K .......... .......... .......... .......... .......... 97%  817K 1s\n",
            " 15450K .......... .......... .......... .......... .......... 97%  542K 1s\n",
            " 15500K .......... .......... .......... .......... .......... 97% 2,43M 1s\n",
            " 15550K .......... .......... .......... .......... .......... 97%  505K 1s\n",
            " 15600K .......... .......... .......... .......... .......... 98%  967K 1s\n",
            " 15650K .......... .......... .......... .......... .......... 98%  878K 1s\n",
            " 15700K .......... .......... .......... .......... .......... 98%  930K 0s\n",
            " 15750K .......... .......... .......... .......... .......... 99%  961K 0s\n",
            " 15800K .......... .......... .......... .......... .......... 99%  876K 0s\n",
            " 15850K .......... .......... .......... .......... .......... 99%  535K 0s\n",
            " 15900K .......... .......... ..                              100% 2,98M=40s\n",
            "\n",
            "2025-02-09 17:53:30 (397 KB/s) - 'rus-eng.zip' saved [16305013/16305013]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/rus-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.rename('rus.txt', 'eng-rus.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(r\"D:\\Progect\\RNN\\rus-eng.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"D:\\Progect\\RNN\")       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "colab_type": "code",
        "id": "twIcAJnyRkW-",
        "outputId": "aae61acf-df6c-4443-8eaa-61a0be531bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
            "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
            "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ],
      "source": [
        "with open(r\"D:\\Progect\\RNN\\eng-rus.txt\", 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines[-10:]:  # Shows last 10 lines\n",
        "        print(line.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Выполним предварительную обработку данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kyNnJyruM9t1"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0   # Start of sequence\n",
        "EOS_token = 1   # End of sequence\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FXKs8j4bM9t6"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^а-яА-Я.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D8T4VxZeM9t-"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eBOwgEBdM9uB"
      },
      "outputs": [],
      "source": [
        "# максимальное количество слов в предложении\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "# Русские префиксы для предложений\n",
        "RUSSIAN_PREFIXES = (\n",
        "    \"я \", \"мы \",\n",
        "    \"он \", \"она \", \"оно \",\n",
        "    \"ты \", \"вы \",\n",
        "    \"они \",\n",
        "    \"это \", \"эти \",\n",
        "    \"тот \", \"та \", \"те \",\n",
        "    \"сейчас \", \"теперь \",\n",
        "    \"вот \", \"здесь \",\n",
        "    \"там \", \"туда \",\n",
        "    \"сюда \", \"отсюда \"\n",
        ")\n",
        "\n",
        "def filter_pair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(RUSSIAN_PREFIXES)\n",
        "\n",
        "def filter_pairs(pairs):\n",
        "    return [pair for pair in pairs if filter_pair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "colab_type": "code",
        "id": "6dZOGjd5M9uE",
        "outputId": "0cdd3a7f-2ac8-4872-8a81-6101d0bdd0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 496059 sentence pairs\n",
            "Trimmed to 183398 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 4\n",
            "eng 30241\n",
            "[' . . ', 'я люблю кошек .', ' .']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filter_pairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Архитектура Seq2Seq-модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "m9vm9QBWM9uI"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PFbuUL1LM9uL"
      },
      "outputs": [],
      "source": [
        "# Decoder\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "z6gGPtXFM9uQ"
      },
      "outputs": [],
      "source": [
        "# преобразуем предложения в список индексов и слов\n",
        "def indexes_from_sentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "# преобразуем предложение в тензор PyTorch\n",
        "def tensor_from_sentence(lang, sentence):\n",
        "    indexes = indexes_from_sentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "# создадим тензоры для пары предложений\n",
        "def tensors_from_pair(pair):\n",
        "    input_tensor = tensor_from_sentence(input_lang, pair[0])\n",
        "    target_tensor = tensor_from_sentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8Fn8VDv8M9uS"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "# обучение модели\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "     # Инициализация\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # Кодирование входного предложения\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    # декодирование\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Обучение с teacher forcing или без него\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "     # Обратное распространение ошибки и обновление моделей\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EKsdwPmSM9uU"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def as_minutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def time_since(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0JXG-RzCM9uZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def show_plot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C_z_k5IiM9uX"
      },
      "outputs": [],
      "source": [
        "# обучение модели\n",
        "def train_iterations(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    # Инициализация оптимизаторов\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Подготовка данных для обучения\n",
        "    training_pairs = [tensors_from_pair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    # Цикл обучения\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        # Получение пары для обучения\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        # Обучение на текущей паре\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        \n",
        "        # Накопление потерь\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "         # Печать статистики\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (time_since(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        # Обновление графика\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    show_plot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3Bxf45h6M9ud"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        # Подготовка входных данных\n",
        "        input_tensor = tensor_from_sentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "\n",
        "        # Инициализация кодировщика\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        # Кодирование входного предложения\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        # Инициализация декодировщика\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "\n",
        "        # Генерация перевода\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1qUmQIGwM9uf"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "colab_type": "code",
        "id": "s_56t10oM9uh",
        "outputId": "f456b0b8-fc35-4199-fb19-b45c2330bf72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11m 9s (- 156m 19s) (5000 6%) 4.7906\n",
            "22m 24s (- 145m 40s) (10000 13%) 4.5216\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train_iterations(encoder1, decoder1, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Оценка модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xEoEylSyM9uj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> je m en sors .\n",
            "= i m managing .\n",
            "< i m managing . <EOS>\n",
            "\n",
            "> vous etes plus intelligent que moi .\n",
            "= you re smarter than me .\n",
            "< you re smarter than me . <EOS>\n",
            "\n",
            "> je suis a bout de souffle .\n",
            "= i m short of breath .\n",
            "< i m familiar of of . <EOS>\n",
            "\n",
            "> elles sont toutes mauvaises .\n",
            "= they re all bad .\n",
            "< they re all bad . <EOS>\n",
            "\n",
            "> j en ai assez de me disputer .\n",
            "= i m tired of arguing .\n",
            "< i m tired of arguing . <EOS>\n",
            "\n",
            "> je suis vraiment desole pour l erreur .\n",
            "= i m very sorry about the mistake .\n",
            "< i m sorry for my mistake . <EOS>\n",
            "\n",
            "> ils vont faire des conneries .\n",
            "= they re up to no good .\n",
            "< they re up to no good . <EOS>\n",
            "\n",
            "> je suis de la cote est .\n",
            "= i m from the east coast .\n",
            "< i m from the mood . <EOS>\n",
            "\n",
            "> je m ennuie a en mourir .\n",
            "= i am bored to death .\n",
            "< i am bored to death . <EOS>\n",
            "\n",
            "> je ne suis pas tres organise .\n",
            "= i m not very organized .\n",
            "< i m not very . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Добавим +1 рекуррентный слой в encoder и decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Архитектура модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderRNN_1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # Добавлен первый GRU слой\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size)\n",
        "        \n",
        "        # Добавлен второй GRU слой\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output = embedded\n",
        "\n",
        "        # Пропуск через первый GRU слой\n",
        "        output, hidden1 = self.gru1(output, hidden)\n",
        "        \n",
        "        # Пропуск через второй GRU слой\n",
        "        output, hidden2 = self.gru2(output, hidden1)\n",
        "        \n",
        "        return output, hidden2\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DecoderRNN_1(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        \n",
        "        # Добавлен первый GRU слой\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size)\n",
        "        \n",
        "        # Добавлен второй GRU слой\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        \n",
        "        # Пропуск через первый GRU слой\n",
        "        output, hidden1 = self.gru1(output, hidden)\n",
        "        \n",
        "        # Пропуск через второй GRU слой\n",
        "        output, hidden2 = self.gru2(output, hidden1)\n",
        "        \n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden2\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hidden_size = 256\n",
        "encoder_1 = EncoderRNN_1(input_lang.n_words, hidden_size).to(device)\n",
        "decoder_1 = DecoderRNN_1(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train_iterations(encoder_1, decoder_1, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Заменим GRU на LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Архитектура модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderRNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        \n",
        "        # Заменены GRU на LSTM\n",
        "        self.lstm1 = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n",
        "        \n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        \n",
        "        # Обработка через первичный LSTM\n",
        "        output, hidden1 = self.lstm1(output, hidden)\n",
        "        \n",
        "        # Обработка через вторичный LSTM\n",
        "        output, hidden2 = self.lstm2(output, hidden1)\n",
        "        \n",
        "        return output, hidden2\n",
        "    def init_hidden(self):\n",
        "        return (\n",
        "            torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "            torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DecoderRNN_LSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        \n",
        "        # Заменены GRU на LSTM\n",
        "        self.lstm1 = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        \n",
        "        # Обработка через первичный LSTM\n",
        "        output, hidden1 = self.lstm1(output, hidden)\n",
        "        \n",
        "        # Обработка через вторичный LSTM\n",
        "        output, hidden2 = self.lstm2(output, hidden1)\n",
        "        \n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hidden_size = 256\n",
        "encoder_lstm = EncoderRNN_LSTM(input_lang.n_words, hidden_size).to(device)\n",
        "decoder_lstm = DecoderRNN_LSTM(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train_iterations(encoder_lstm, decoder_lstm, 75000, print_every=5000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Лекция 8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
