{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ogC3QmqKn1"
      },
      "source": [
        "### В этой работе:\n",
        "1. Скачаем [датасет](https://www.manythings.org/anki/rus-eng.zip) англо-русскую пару фраз\n",
        "2. Обучим seq2seq модель.\n",
        "3. Поэкспериментируем с различными слоями RNN, GRU и LSTM\n",
        "4. Оценим качество модели\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpq4MzorqKn3"
      },
      "source": [
        "### Загрузим данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-YlRH3mQM9tf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MIEGXF8oM9tt"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UKlPFcBNZl5",
        "outputId": "60320b48-dffe-4f3e-8c46-cbc94a70937e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-11 19:23:58--  https://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16305013 (16M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  15.55M  32.8MB/s    in 0.5s    \n",
            "\n",
            "2025-02-11 19:23:58 (32.8 MB/s) - ‘rus-eng.zip’ saved [16305013/16305013]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# загрузим данные\n",
        "!wget https://www.manythings.org/anki/rus-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGQChB7nqKn6"
      },
      "outputs": [],
      "source": [
        "# распакуем\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(r\"D:\\Progect\\RNN\\rus-eng.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"D:\\Progect\\RNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twIcAJnyRkW-",
        "outputId": "f25f85f8-1b0c-4027-fe82-678cfcf1fd2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
            "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
            "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ],
      "source": [
        "# смотрим что внутри, выведем последние 10 строк текста\n",
        "with open(r\"/content/eng-rus.txt\", 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines[-10:]:  # Shows last 10 lines\n",
        "        print(line.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlvU5MPnqKn6"
      },
      "source": [
        "### Выполним предварительную обработку данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kyNnJyruM9t1"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0   # Start of sequence\n",
        "EOS_token = 1   # End of sequence\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FXKs8j4bM9t6"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "\n",
        "# Удалим диакритические знаки\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'  # проверяем, что категория символа c не является \"Mn\" (Mark, Nonspacing), то есть это не диакритический знак.\n",
        "    )\n",
        "\n",
        "# проведем предобработку текста\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    # s = re.sub(r\"[^а-яА-Я.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D8T4VxZeM9t-"
      },
      "outputs": [],
      "source": [
        "# прочитаем текст с парами предложений\n",
        "# флаг reverse, указывает нужно ли поменять язык местами\n",
        "# если  reverse=True - меняем порядок предложений в каждой паре\n",
        "# если reverse=False - оставляем порядок предложений без изменений\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Прочитаем текст построчно\n",
        "    # разделитель в тексте разный, в моем случаее это CC-BY\n",
        "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    lines = [i.split('\\tCC-BY', 1)[0] for i in lines]\n",
        "\n",
        "    # Соеденим каждую строку в пару предложений, проведем нормализацию текста\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Возвращаем список пар слов\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eBOwgEBdM9uB"
      },
      "outputs": [],
      "source": [
        "# максимальное количество слов в предложении\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "# Префиксы для предложений\n",
        "ENGLISH_PREFIXES = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filter_pair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(ENGLISH_PREFIXES)\n",
        "\n",
        "def filter_pairs(pairs):\n",
        "    return [pair for pair in pairs if filter_pair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dZOGjd5M9uE",
        "outputId": "49f8d066-f574-491b-8197-8cc5e9ae6416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 496059 sentence pairs\n",
            "Trimmed to 5113 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 4792\n",
            "eng 2446\n",
            "['она истинно обворожительнеишая молодая леди .', 'she is a most charming young lady indeed .']\n"
          ]
        }
      ],
      "source": [
        "# функция подготовки данных для машинного перевода\n",
        "# lang1 и lang2 - коды языков (например, 'eng' для английского, 'rus' для русского)\n",
        "# reverse=False - направление перевода\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "\n",
        "    # выведим количество прочитанных пар предложений\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    # выведим количество пар предложений после фильтрации\n",
        "    pairs = filter_pairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    # выводит имя языка и количество уникальных слов\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "# параметры машинного перевода: 'eng' - английский язык, 'rus' - русский язык\n",
        "# True - перевод будет осуществляться с русского на английский\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "\n",
        "# проверим корректность работы функции\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прочитали 496 059 пар предложений   \n",
        "После фильтрации осталось 5113 пар предложений   \n",
        "Посчитали количество уникальных пар предложений:   \n",
        "для русского языка - 4792   \n",
        "для английского языка - 2446   \n",
        "\n",
        "При этом, если мы изменим параметр MAX_LENGTH больше чем 20, тогда получим большее число уникальных предложений, если уменьшим, то, соответственно получим меньшее количество уникальных предложений"
      ],
      "metadata": {
        "id": "trBWcGm0kNIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------\n",
        "Если на этом этапе в результате предобработки мы увидели корректный текст на двух разных языках (в нашем варианте 'eng'и 'rus'), тогда можно приступать к следующему шагу, к созданию архитектуры модели и её обучению.    \n",
        "Если до этого момента на выходе получили непонятный текст или ошибку, то следует вернуться к повторной обработке данных, пока не получим корректный результат."
      ],
      "metadata": {
        "id": "IVER9Pc4f6VF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upw8QbDvqKn8"
      },
      "source": [
        "### Архитектура GRU-модели c одним слоем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m9vm9QBWM9uI"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PFbuUL1LM9uL"
      },
      "outputs": [],
      "source": [
        "# Decoder\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z6gGPtXFM9uQ"
      },
      "outputs": [],
      "source": [
        "# преобразуем предложения в список индексов и слов\n",
        "def indexes_from_sentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "# преобразуем предложение в тензор PyTorch\n",
        "def tensor_from_sentence(lang, sentence):\n",
        "    indexes = indexes_from_sentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "# создадим тензоры для пары предложений\n",
        "def tensors_from_pair(pair):\n",
        "    input_tensor = tensor_from_sentence(input_lang, pair[0])\n",
        "    target_tensor = tensor_from_sentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8Fn8VDv8M9uS"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "     # Инициализация\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # Кодирование входного предложения\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    # декодирование\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Обучение с teacher forcing или без него\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    # Обратное распространение ошибки и обновление моделей\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EKsdwPmSM9uU"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def as_minutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def time_since(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0JXG-RzCM9uZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def show_plot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nVrqw41qKn-"
      },
      "source": [
        "#### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "C_z_k5IiM9uX"
      },
      "outputs": [],
      "source": [
        "# обучение модели\n",
        "def train_iterations(\n",
        "    encoder,           # модель-кодировщик\n",
        "    decoder,          # модель-декодировщик\n",
        "    n_iters,          # количество итераций\n",
        "    print_every=1000, # интервал печати статистики\n",
        "    plot_every=100,   # интервал обновления графика\n",
        "    learning_rate=0.01 # скорость обучения\n",
        "):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    # Инициализация оптимизаторов\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Подготовка данных для обучения\n",
        "    training_pairs = [tensors_from_pair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    # Цикл обучения\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        # Получение пары для обучения\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        # Обучение на текущей паре\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "        # Накопление потерь\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "         # Печать статистики\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (time_since(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        # Обновление графика\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    show_plot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3Bxf45h6M9ud"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        # Подготовка входных данных\n",
        "        input_tensor = tensor_from_sentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "\n",
        "        # Инициализация кодировщика\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        # Кодирование входного предложения\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        # Инициализация декодировщика\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "\n",
        "        # Генерация перевода\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1qUmQIGwM9uf"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_56t10oM9uh",
        "outputId": "1eb209af-f5d8-4a01-a347-038d33908e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 17s (- 18m 11s) (5000 6%) 3.0949\n",
            "2m 26s (- 15m 54s) (10000 13%) 2.5096\n",
            "3m 37s (- 14m 29s) (15000 20%) 2.0018\n",
            "4m 47s (- 13m 9s) (20000 26%) 1.6168\n",
            "5m 57s (- 11m 55s) (25000 33%) 1.2623\n",
            "7m 8s (- 10m 43s) (30000 40%) 0.9882\n",
            "8m 19s (- 9m 30s) (35000 46%) 0.7511\n",
            "9m 30s (- 8m 19s) (40000 53%) 0.5693\n",
            "10m 42s (- 7m 8s) (45000 60%) 0.4360\n",
            "11m 53s (- 5m 56s) (50000 66%) 0.3229\n",
            "13m 4s (- 4m 45s) (55000 73%) 0.2308\n",
            "14m 16s (- 3m 34s) (60000 80%) 0.1619\n",
            "15m 27s (- 2m 22s) (65000 86%) 0.1282\n",
            "16m 38s (- 1m 11s) (70000 93%) 0.0975\n",
            "17m 50s (- 0m 0s) (75000 100%) 0.0768\n"
          ]
        }
      ],
      "source": [
        "# зададим параметр скрытого состояния, это влияет на способность модели запоминать контекст\n",
        "# больший размер даёт больше возможностей для хранения информации, но увеличивает вычислительные затраты\n",
        "hidden_size = 256\n",
        "encoderRNN = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoderRNN = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "# 75000 - количество итераций обучения\n",
        "# print_every=5000 - каждые 5000 итераций будет выводиться статистика обучения\n",
        "train_iterations(encoderRNN, decoderRNN, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ8pk7s5qKn_"
      },
      "source": [
        "#### Оценка модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEoEylSyM9uj",
        "outputId": "7d79c7e5-299a-470f-dba9-38887c6b6825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> ты неодета .\n",
            "= you aren't dressed .\n",
            "< you aren't dressed . <EOS>\n",
            "\n",
            "> он такого же роста, как мои отец .\n",
            "= he is as tall as my father .\n",
            "< he is as tall as my father . <EOS>\n",
            "\n",
            "> они летчицы .\n",
            "= they are pilots .\n",
            "< they are pilots . <EOS>\n",
            "\n",
            "> я под одеялом .\n",
            "= i am under the blanket .\n",
            "< i am under the blanket . <EOS>\n",
            "\n",
            "> она не так молода, как выглядит .\n",
            "= she is not as young as she looks .\n",
            "< she is not as young as she looks . <EOS>\n",
            "\n",
            "> его там нет .\n",
            "= he is not there .\n",
            "< he is not there . <EOS>\n",
            "\n",
            "> его все уважают .\n",
            "= he is respected by everyone .\n",
            "< he is respected by everyone . <EOS>\n",
            "\n",
            "> еи за двадцать .\n",
            "= she is over twenty .\n",
            "< she is over twenty . <EOS>\n",
            "\n",
            "> он беден, но счастлив .\n",
            "= he is poor, but happy .\n",
            "< he is poor, but happy . <EOS>\n",
            "\n",
            "> она показала мне свои альбом .\n",
            "= she showed me her album .\n",
            "< she showed me her album . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoderRNN, decoderRNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ORvm5eDqKoA"
      },
      "source": [
        "### Добавим RNN слой в encoder и decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HY9OdnPqKoA"
      },
      "source": [
        "#### Архитектура модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H25iSM9AqKoA"
      },
      "outputs": [],
      "source": [
        "class EncoderGRU_RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderGRU_RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # Первый GRU слой\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "        # Добавлен второй RNN слой\n",
        "        self.gru2 = nn.RNN(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output = embedded\n",
        "\n",
        "        # Пропуск через первый GRU слой\n",
        "        output, hidden1 = self.gru1(output, hidden)\n",
        "\n",
        "        # Пропуск через второй RNN слой\n",
        "        output, hidden2 = self.gru2(output, hidden1)\n",
        "\n",
        "        return output, hidden2\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Wmyd0_rYqKoA"
      },
      "outputs": [],
      "source": [
        "class DecoderGRU_RNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderGRU_RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # Первый GRU слой\n",
        "        self.gru1 = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "        # Добавлен второй RNN слой\n",
        "        self.gru2 = nn.RNN(hidden_size, hidden_size)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        # Пропуск через первый GRU слой\n",
        "        output, hidden1 = self.gru1(output, hidden)\n",
        "\n",
        "        # Пропуск через второй RNN слой\n",
        "        output, hidden2 = self.gru2(output, hidden1)\n",
        "\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden2\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcifE_M-qKoB"
      },
      "source": [
        "#### Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MmWOj9QsqKoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9943fe-0fdf-46f1-8b21-9d58fa6a5fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 57s (- 27m 19s) (5000 6%) 3.3869\n",
            "3m 40s (- 23m 50s) (10000 13%) 3.0830\n",
            "5m 21s (- 21m 26s) (15000 20%) 3.0266\n",
            "7m 7s (- 19m 34s) (20000 26%) 2.9329\n",
            "8m 49s (- 17m 39s) (25000 33%) 2.9363\n",
            "10m 32s (- 15m 49s) (30000 40%) 2.9706\n",
            "12m 20s (- 14m 6s) (35000 46%) 2.9119\n",
            "14m 4s (- 12m 18s) (40000 53%) 2.8476\n",
            "15m 47s (- 10m 31s) (45000 60%) 2.8544\n",
            "17m 27s (- 8m 43s) (50000 66%) 2.8446\n",
            "19m 8s (- 6m 57s) (55000 73%) 2.8819\n",
            "20m 47s (- 5m 11s) (60000 80%) 2.8957\n",
            "22m 26s (- 3m 27s) (65000 86%) 2.9330\n",
            "24m 6s (- 1m 43s) (70000 93%) 2.9857\n",
            "25m 45s (- 0m 0s) (75000 100%) 2.9260\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoderGRU_RNN = EncoderGRU_RNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoderGRU_RNN = DecoderGRU_RNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train_iterations(encoderGRU_RNN, decoderGRU_RNN, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoderGRU_RNN, decoderGRU_RNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4gdOK_7n_uW",
        "outputId": "35d8123d-8232-4ef4-b30a-859aed293190"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> она очень стеснительная девочка .\n",
            "= she is a very shy girl .\n",
            "< she is going to . <EOS>\n",
            "\n",
            "> она беспокоится о твоем здоровье .\n",
            "= she is anxious about your health .\n",
            "< she is no to <EOS>\n",
            "\n",
            "> она держит ложку левои рукои .\n",
            "= she is holding a ladle with her left hand .\n",
            "< she is not to . <EOS>\n",
            "\n",
            "> только тебе я могу доверять .\n",
            "= you are the only one i can trust .\n",
            "< they aren't used to . <EOS>\n",
            "\n",
            "> мы с неи помолвлены .\n",
            "= i am engaged to her .\n",
            "< she is going to . <EOS>\n",
            "\n",
            "> она страдает от низкого кровяного давления .\n",
            "= she suffers from low blood pressure .\n",
            "< she is going to . <EOS>\n",
            "\n",
            "> ты очень храбрыи .\n",
            "= you are very brave .\n",
            "< you are a . <EOS>\n",
            "\n",
            "> она уже не та, какои была десять лет назад .\n",
            "= she is not what she was ten years ago .\n",
            "< she is going to . <EOS>\n",
            "\n",
            "> я ищу подарок маме .\n",
            "= i am looking for a present for my mother .\n",
            "< you are a . <EOS>\n",
            "\n",
            "> они изучают проблему .\n",
            "= they are looking into the problem .\n",
            "< they aren't used to . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMCuVVqgqKoB"
      },
      "source": [
        "### Заменим на LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwd-XUUAqKoB"
      },
      "source": [
        "#### Архитектура модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nFBgmZgAqKoB"
      },
      "outputs": [],
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # Заменены на LSTM\n",
        "        self.lstm1 = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output = embedded\n",
        "\n",
        "        # Обработка через первичный LSTM\n",
        "        output, hidden1 = self.lstm1(output, hidden)\n",
        "\n",
        "        # Обработка через вторичный LSTM\n",
        "        output, hidden2 = self.lstm2(output, hidden1)\n",
        "\n",
        "        return output, hidden2\n",
        "    def init_hidden(self):\n",
        "        return (\n",
        "            torch.zeros(1, 1, self.hidden_size, device=device),\n",
        "            torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WnqXKX0CqKoB"
      },
      "outputs": [],
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # Заменены на LSTM\n",
        "        self.lstm1 = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        # Обработка через первичный LSTM\n",
        "        output, hidden1 = self.lstm1(output, hidden)\n",
        "\n",
        "        # Обработка через вторичный LSTM\n",
        "        output, hidden2 = self.lstm2(output, hidden1)\n",
        "\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4C3hTWXqKoC"
      },
      "source": [
        "#### Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oz-U1SH_qKoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9540f4d2-4517-48a7-92ab-3ad0e5ef1ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 9s (- 30m 16s) (5000 6%) 3.4496\n",
            "4m 11s (- 27m 14s) (10000 13%) 3.1889\n",
            "6m 13s (- 24m 54s) (15000 20%) 3.1088\n",
            "8m 15s (- 22m 42s) (20000 26%) 2.8794\n",
            "10m 18s (- 20m 37s) (25000 33%) 2.7006\n",
            "12m 22s (- 18m 33s) (30000 40%) 2.5756\n",
            "14m 26s (- 16m 30s) (35000 46%) 2.5181\n",
            "16m 33s (- 14m 29s) (40000 53%) 2.4540\n",
            "18m 39s (- 12m 26s) (45000 60%) 2.3876\n",
            "20m 46s (- 10m 23s) (50000 66%) 2.3070\n",
            "22m 54s (- 8m 19s) (55000 73%) 2.2122\n",
            "25m 2s (- 6m 15s) (60000 80%) 2.1535\n",
            "27m 11s (- 4m 10s) (65000 86%) 2.0386\n",
            "29m 19s (- 2m 5s) (70000 93%) 1.9723\n",
            "31m 28s (- 0m 0s) (75000 100%) 1.8676\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoderLSTM = EncoderLSTM(input_lang.n_words, hidden_size).to(device)\n",
        "decoderLSTM = DecoderLSTM(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train_iterations(encoderLSTM, decoderLSTM, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoderLSTM, decoderLSTM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGNn36s4DFZx",
        "outputId": "0761ca6c-9c86-43de-9617-e155a75fec4a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> мы находимся под его командованием .\n",
            "= we are under his command .\n",
            "< we are looking forward . <EOS>\n",
            "\n",
            "> он катается на коньках .\n",
            "= he is skating .\n",
            "< he is good in the . . <EOS>\n",
            "\n",
            "> я рад слышать эти известия .\n",
            "= i am glad to hear the news .\n",
            "< i am afraid that i will you . . <EOS>\n",
            "\n",
            "> он вооружен до зубов .\n",
            "= he is armed to the teeth .\n",
            "< he is going to the . . <EOS>\n",
            "\n",
            "> только тебе я могу доверять .\n",
            "= you are the only one i can trust .\n",
            "< you are the last person that i expected . <EOS>\n",
            "\n",
            "> они обеспеченные люди .\n",
            "= they are well off .\n",
            "< they are all . <EOS>\n",
            "\n",
            "> с ним тяжело иметь дело .\n",
            "= he is hard to deal with .\n",
            "< he is too young at the . . <EOS>\n",
            "\n",
            "> вы ведь нам не все рассказываете ?\n",
            "= you aren't telling us everything, are you ?\n",
            "< you aren't mad at me, are you ? <EOS>\n",
            "\n",
            "> я до конца сентября работаю на полную ставку в книжном магазине .\n",
            "= i am working full-time at a bookshop until the end of september .\n",
            "< i am looking to be a in the the the the the the the . <EOS>\n",
            "\n",
            "> она такого же роста, как и вы .\n",
            "= she is as tall as you .\n",
            "< she is as beautiful as you . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Итоги:"
      ],
      "metadata": {
        "id": "zt9ZwHhkz2Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'time': ['17m 50s', '25m 45s', '31m 28s'],\n",
        "    'loss_avg': [0.0768, 2.9260, 1.8676]\n",
        "}\n",
        "df = pd.DataFrame(data, index=['GRU', 'GRU_RNN', 'LSTM'])\n",
        "df\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "9SLGPbVmwU-Q",
        "outputId": "7bf6061b-6597-43c8-d818-6b5857f11883"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            time  loss_avg\n",
              "GRU      17m 50s    0.0768\n",
              "GRU_RNN  25m 45s    2.9260\n",
              "LSTM     31m 28s    1.8676"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65e1a252-3ebc-43c2-9160-6bb73d43f207\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>loss_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>17m 50s</td>\n",
              "      <td>0.0768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU_RNN</th>\n",
              "      <td>25m 45s</td>\n",
              "      <td>2.9260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>31m 28s</td>\n",
              "      <td>1.8676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65e1a252-3ebc-43c2-9160-6bb73d43f207')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65e1a252-3ebc-43c2-9160-6bb73d43f207 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65e1a252-3ebc-43c2-9160-6bb73d43f207');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab7028ab-ec3e-49d1-b007-139dc30d7510\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab7028ab-ec3e-49d1-b007-139dc30d7510')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab7028ab-ec3e-49d1-b007-139dc30d7510 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"17m 50s\",\n          \"25m 45s\",\n          \"31m 28s\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4402034485909736,\n        \"min\": 0.0768,\n        \"max\": 2.926,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0768,\n          2.926,\n          1.8676\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Напомню исходные данные:**\n",
        "1. GRU: состоит из одного слоя\n",
        "2. GRU_RNN: состоит из одного слоя GRU и одного слоя RNN\n",
        "3. LSTM: состоит из двух слоев LSTM\n",
        "\n",
        "**Анализ результатов:**\n",
        "\n",
        "*GRU:*   \n",
        "* Показал наилучшие результаты по loss (0.0768)\n",
        "* Самая быстрая скорость обучения (17м 50с)\n",
        "* Это ожидаемо, так как GRU имеет упрощенную архитектуру\n",
        "\n",
        "*GRU_RNN:*   \n",
        "* Наихудший loss (2.9260)\n",
        "* Средняя скорость обучения (25м 45с)\n",
        "* Комбинированная архитектура не улучшила результаты\n",
        "\n",
        "*LSTM:*\n",
        "* Средний loss (1.8676)\n",
        "* Самая долгая тренировка (31м 28с)\n",
        "* Более сложная архитектура требует больше времени\n",
        "\n",
        "**Выводы:**\n",
        "\n",
        "GRU показал оптимальный баланс между скоростью и качеством обучения.\n",
        "Возможно при увеличении объема данных LSTM получила бы преимущество, т.к. loss снижался с 3.4496 до 1.8676. Я считаю, что в этом есть потенциал увеличения качества модели, т.к. я намеренно усложнил модель двумя слоями LSTM, против одного слоя GRU.   \n",
        "\n",
        "Используем GRU для небольших наборов данных, используем LSTM при наличии достаточного объема данных и вычислительных ресурсов, комбинированные архитектуры в моем случае не показали явных преимуществ."
      ],
      "metadata": {
        "id": "XBQtKReu5NFh"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}