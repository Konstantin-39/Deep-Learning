{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "Сгенерировать последовательности, которые бы состояли из цифр (от 0 до 9) и задавались следующим образом:   \n",
    "x - последовательность цифр   \n",
    "y1 = x1, y(i) = x(i) + x(1). Если y(i) >= 10, то y(i) = y(i) - 10\n",
    "\n",
    "**Задача:**\n",
    "1. научить модель предсказывать y(i) по x(i)\n",
    "2. пробовать RNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(length):\n",
    "    x = np.random.randint(0, 10, length)\n",
    "    y = np.zeros_like(x)\n",
    "    y[0] = x[0]\n",
    "    for i in range(1, length):\n",
    "        y[i] = x[i] + x[0]\n",
    "        if y[i] >= 10:\n",
    "            y[i] -= 10\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация набора данных\n",
    "data_size = 10000\n",
    "sequence_length = 10\n",
    "X = []\n",
    "Y = []\n",
    "for _ in range(data_size):\n",
    "    x, y = generate_sequence(sequence_length)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "X = np.array(X, dtype=int)\n",
    "Y = np.array(Y, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 4, 6, ..., 7, 2, 9],\n",
       "       [8, 1, 2, ..., 0, 0, 6],\n",
       "       [1, 2, 0, ..., 9, 3, 9],\n",
       "       ...,\n",
       "       [1, 8, 4, ..., 4, 8, 5],\n",
       "       [2, 6, 6, ..., 4, 9, 9],\n",
       "       [0, 7, 3, ..., 3, 4, 7]], shape=(10000, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим получившыйся набор данных Х\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 1, 3, ..., 4, 9, 6],\n",
       "       [8, 9, 0, ..., 8, 8, 4],\n",
       "       [1, 3, 1, ..., 0, 4, 0],\n",
       "       ...,\n",
       "       [1, 9, 5, ..., 5, 9, 6],\n",
       "       [2, 8, 8, ..., 6, 1, 1],\n",
       "       [0, 7, 3, ..., 3, 4, 7]], shape=(10000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим получившыйся набор данных Y\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Подготовка данных\n",
    "Разделим данные на обучающую и тестовую выборки и преобразуем их в тензоры PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Преобразование данных в тензоры Pytorch\n",
    "X_train = torch.Tensor(X_train).unsqueeze(-1) # Добавляем размерность для признаков\n",
    "X_test = torch.Tensor(X_test).unsqueeze(-1)\n",
    "Y_train = torch.Tensor(Y_train) \n",
    "Y_test = torch.Tensor(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим DataLoader\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Создание модели\n",
    "Создадим модели RNN, LSTM и GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class GRU_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU_Model, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели\n",
    "input_size = 1\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем модели\n",
    "rnn_model = RNN_Model(input_size, hidden_size, output_size)\n",
    "lstm_model = LSTM_Model(input_size, hidden_size, output_size)\n",
    "gru_model = GRU_Model(input_size, hidden_size, output_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция потерь и оптимизатор\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "num_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN Model...\n",
      "Epoch [1/20], loss: 8.894\n",
      "Epoch [2/20], loss: 8.554\n",
      "Epoch [3/20], loss: 8.421\n",
      "Epoch [4/20], loss: 7.336\n",
      "Epoch [5/20], loss: 8.525\n",
      "Epoch [6/20], loss: 8.727\n",
      "Epoch [7/20], loss: 9.019\n",
      "Epoch [8/20], loss: 8.749\n",
      "Epoch [9/20], loss: 8.566\n",
      "Epoch [10/20], loss: 8.035\n",
      "Epoch [11/20], loss: 8.626\n",
      "Epoch [12/20], loss: 8.391\n",
      "Epoch [13/20], loss: 8.735\n",
      "Epoch [14/20], loss: 8.078\n",
      "Epoch [15/20], loss: 8.748\n",
      "Epoch [16/20], loss: 7.889\n",
      "Epoch [17/20], loss: 8.185\n",
      "Epoch [18/20], loss: 8.562\n",
      "Epoch [19/20], loss: 8.137\n",
      "Epoch [20/20], loss: 8.541\n",
      "Training LSTM Model...\n",
      "Epoch [1/20], loss: 7.972\n",
      "Epoch [2/20], loss: 8.006\n",
      "Epoch [3/20], loss: 8.188\n",
      "Epoch [4/20], loss: 8.992\n",
      "Epoch [5/20], loss: 7.527\n",
      "Epoch [6/20], loss: 7.233\n",
      "Epoch [7/20], loss: 7.320\n",
      "Epoch [8/20], loss: 7.614\n",
      "Epoch [9/20], loss: 6.827\n",
      "Epoch [10/20], loss: 7.424\n",
      "Epoch [11/20], loss: 7.845\n",
      "Epoch [12/20], loss: 7.396\n",
      "Epoch [13/20], loss: 7.095\n",
      "Epoch [14/20], loss: 6.912\n",
      "Epoch [15/20], loss: 6.606\n",
      "Epoch [16/20], loss: 6.428\n",
      "Epoch [17/20], loss: 6.646\n",
      "Epoch [18/20], loss: 6.082\n",
      "Epoch [19/20], loss: 5.915\n",
      "Epoch [20/20], loss: 6.220\n",
      "Training GRU Model...\n",
      "Epoch [1/20], loss: 8.289\n",
      "Epoch [2/20], loss: 7.642\n",
      "Epoch [3/20], loss: 8.792\n",
      "Epoch [4/20], loss: 8.189\n",
      "Epoch [5/20], loss: 7.058\n",
      "Epoch [6/20], loss: 7.761\n",
      "Epoch [7/20], loss: 6.926\n",
      "Epoch [8/20], loss: 7.229\n",
      "Epoch [9/20], loss: 7.298\n",
      "Epoch [10/20], loss: 4.939\n",
      "Epoch [11/20], loss: 4.938\n",
      "Epoch [12/20], loss: 3.789\n",
      "Epoch [13/20], loss: 3.600\n",
      "Epoch [14/20], loss: 3.070\n",
      "Epoch [15/20], loss: 1.767\n",
      "Epoch [16/20], loss: 1.670\n",
      "Epoch [17/20], loss: 1.196\n",
      "Epoch [18/20], loss: 0.758\n",
      "Epoch [19/20], loss: 0.644\n",
      "Epoch [20/20], loss: 0.409\n"
     ]
    }
   ],
   "source": [
    "# Обучим модель\n",
    "def train_model(model, train_loader, num_epochs=num_epoch):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], loss: {loss.item():.3f}\")\n",
    "\n",
    "print(\"Training RNN Model...\")\n",
    "train_model(rnn_model, train_loader)\n",
    "\n",
    "print(\"Training LSTM Model...\")\n",
    "train_model(lstm_model, train_loader)\n",
    "\n",
    "print(\"Training GRU Model...\")\n",
    "train_model(gru_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Оценка моделей\n",
    "Протестируем модели на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RNN Model...\n",
      "test loss: 8.221\n",
      "Evaluating LSTM Model...\n",
      "test loss: 5.693\n",
      "Evaluating GRU Model...\n",
      "test loss: 0.463\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss +=loss.item()\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f\"test loss: {avg_loss:.3f}\")\n",
    "\n",
    "print(\"Evaluating RNN Model...\")\n",
    "evaluate_model(rnn_model, test_loader)\n",
    "\n",
    "print(\"Evaluating LSTM Model...\")\n",
    "evaluate_model(lstm_model, test_loader)\n",
    "\n",
    "print(\"Evaluating GRU Model...\")\n",
    "evaluate_model(gru_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. предсказание\n",
    "Используем обученные модели для предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True y: [8. 1. 2. 7. 2. 3. 7. 5. 1. 3.]\n",
      "RNN Predicted y: [4.614479  4.3671975 4.534924  4.5111637 4.4964504 4.555177  4.5321836\n",
      " 4.3942285 4.598049  4.4931517]\n",
      "LSTM Predicted y: [7.853002  1.1469796 3.1693492 3.5572238 3.4494476 3.5780272 4.0179214\n",
      " 3.7534535 4.370585  3.9545755]\n",
      "GRU Predicted y: [7.845748   1.220295   2.0333028  6.8348293  1.7372798  3.2303944\n",
      " 6.318702   5.699797   0.23314214 3.1794047 ]\n"
     ]
    }
   ],
   "source": [
    "def predict_sequence(model, x):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(x).unsqueeze(0).unsqueeze(-1)\n",
    "        y_pred = model(x)\n",
    "    return y_pred.squeeze().numpy()\n",
    "\n",
    "# Пример предсказания\n",
    "x_test = X_test[0].squeeze().numpy()\n",
    "y_test = Y_test[0].numpy()\n",
    "\n",
    "y_pred_rnn = predict_sequence(rnn_model, x_test)\n",
    "y_pred_lstm = predict_sequence(lstm_model, x_test)\n",
    "y_pred_gru = predict_sequence(gru_model, x_test)\n",
    "\n",
    "print(f\"True y: {y_test}\")\n",
    "print(f\"RNN Predicted y: {y_pred_rnn}\")\n",
    "print(f\"LSTM Predicted y: {y_pred_lstm}\")\n",
    "print(f\"GRU Predicted y: {y_pred_gru}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2 (дополнительное и необязательное)\n",
    "применить LSTM для решения лекционного практического [задания](colab.research.google.com...mRGTSSeICL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
