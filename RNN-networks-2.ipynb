{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "Сгенерировать последовательности, которые бы состояли из цифр (от 0 до 9) и задавались следующим образом:   \n",
    "x - последовательность цифр   \n",
    "y[0] = x[0],   \n",
    "y[i] = x[i] + x[0]   \n",
    "Если y[i] >= 10, то y[i] = y[i] - 10\n",
    "\n",
    "**Задача:**\n",
    "1. научить модель предсказывать y(i) по x(i)\n",
    "2. пробовать RNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(length):\n",
    "    x = np.random.randint(0, 10, length)\n",
    "    y = np.zeros_like(x)\n",
    "    y[0] = x[0]\n",
    "    for i in range(1, length):\n",
    "        y[i] = x[i] + x[0]\n",
    "        if y[i] >= 10:\n",
    "            y[i] -= 10\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация набора данных\n",
    "data_size = 10000\n",
    "sequence_length = 10\n",
    "\n",
    "X = np.zeros((data_size, sequence_length), dtype=int)\n",
    "Y = np.zeros_like(X)\n",
    "for i in range(data_size):\n",
    "    x, y = generate_sequence(sequence_length)\n",
    "    X[i] = x\n",
    "    Y[i] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим набор данных Х\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим набор данных Y\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Подготовка данных\n",
    "Разделим данные на обучающую и тестовую выборки и преобразуем их в тензоры PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Преобразование данных в тензоры Pytorch\n",
    "X_train = torch.Tensor(X_train).unsqueeze(-1) # Добавляем размерность для признаков\n",
    "X_test = torch.Tensor(X_test).unsqueeze(-1)\n",
    "Y_train = torch.Tensor(Y_train) \n",
    "Y_test = torch.Tensor(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 3 5 7 2 3 1 4 6]\n",
      "[4 4 7 9 1 6 7 5 8 0]\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим получившуюся матрицу\n",
    "# Возьмем первый элемент матрицы\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим условие:   \n",
    "массив х состоит из случайных чисел от 0 до 9   \n",
    "y[0] = x[0] = 4   \n",
    "y[1] = x[1] + x[0] = 0 + 4 = 4   \n",
    "y[2] = x[2] + x[0] = 3 + 4 = 7   \n",
    "y[3] = x[3] + x[0] = 5 + 4 = 9   \n",
    "y[4] = x[4] + x[0] = 7 + 4 = 11 т.к. 11 > 10, тогда y[4] = 11 - 10 = 1   \n",
    "и т.д.   \n",
    "\n",
    "Генератор работает правильно.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим DataLoader\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Создание модели\n",
    "Создадим модели RNN, LSTM и GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class GRU_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU_Model, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели\n",
    "input_size = 1\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем модели\n",
    "rnn_model = RNN_Model(input_size, hidden_size, output_size)\n",
    "lstm_model = LSTM_Model(input_size, hidden_size, output_size)\n",
    "gru_model = GRU_Model(input_size, hidden_size, output_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция потерь и оптимизатор\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "num_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN Model...\n",
      "Epoch [1/15], loss: 8.449\n",
      "Epoch [2/15], loss: 7.799\n",
      "Epoch [3/15], loss: 8.110\n",
      "Epoch [4/15], loss: 8.263\n",
      "Epoch [5/15], loss: 8.124\n",
      "Epoch [6/15], loss: 7.935\n",
      "Epoch [7/15], loss: 7.663\n",
      "Epoch [8/15], loss: 8.729\n",
      "Epoch [9/15], loss: 7.903\n",
      "Epoch [10/15], loss: 8.083\n",
      "Epoch [11/15], loss: 7.770\n",
      "Epoch [12/15], loss: 8.058\n",
      "Epoch [13/15], loss: 7.764\n",
      "Epoch [14/15], loss: 8.159\n",
      "Epoch [15/15], loss: 8.210\n",
      "==============================\n",
      "Training LSTM Model...\n",
      "Epoch [1/15], loss: 0.007\n",
      "Epoch [2/15], loss: 0.011\n",
      "Epoch [3/15], loss: 0.007\n",
      "Epoch [4/15], loss: 0.010\n",
      "Epoch [5/15], loss: 0.008\n",
      "Epoch [6/15], loss: 0.009\n",
      "Epoch [7/15], loss: 0.009\n",
      "Epoch [8/15], loss: 0.008\n",
      "Epoch [9/15], loss: 0.011\n",
      "Epoch [10/15], loss: 0.009\n",
      "Epoch [11/15], loss: 0.007\n",
      "Epoch [12/15], loss: 0.009\n",
      "Epoch [13/15], loss: 0.010\n",
      "Epoch [14/15], loss: 0.008\n",
      "Epoch [15/15], loss: 0.006\n",
      "==============================\n",
      "Training GRU Model...\n",
      "Epoch [1/15], loss: 0.004\n",
      "Epoch [2/15], loss: 0.004\n",
      "Epoch [3/15], loss: 0.004\n",
      "Epoch [4/15], loss: 0.004\n",
      "Epoch [5/15], loss: 0.006\n",
      "Epoch [6/15], loss: 0.004\n",
      "Epoch [7/15], loss: 0.004\n",
      "Epoch [8/15], loss: 0.005\n",
      "Epoch [9/15], loss: 0.004\n",
      "Epoch [10/15], loss: 0.004\n",
      "Epoch [11/15], loss: 0.004\n",
      "Epoch [12/15], loss: 0.006\n",
      "Epoch [13/15], loss: 0.003\n",
      "Epoch [14/15], loss: 0.003\n",
      "Epoch [15/15], loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "# Обучим модель\n",
    "def train_model(model, train_loader, num_epochs=num_epoch):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], loss: {loss.item():.3f}\")\n",
    "\n",
    "print(\"Training RNN Model...\")\n",
    "train_model(rnn_model, train_loader)\n",
    "print('=' * 30)\n",
    "\n",
    "print(\"Training LSTM Model...\")\n",
    "train_model(lstm_model, train_loader)\n",
    "print('=' * 30) \n",
    "\n",
    "print(\"Training GRU Model...\")\n",
    "train_model(gru_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Оценка моделей\n",
    "Протестируем модели на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель  Test Loss\n",
      "   RNN      8.287\n",
      "  LSTM      0.006\n",
      "   GRU      0.003\n"
     ]
    }
   ],
   "source": [
    "# Создаём словарь с данными\n",
    "data_loss = {\n",
    "    'Модель': ['RNN', 'LSTM', 'GRU'],\n",
    "    'Test Loss': [\n",
    "        evaluate_model(rnn_model, test_loader),\n",
    "        evaluate_model(lstm_model, test_loader),\n",
    "        evaluate_model(gru_model, test_loader)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Создаём датафрейм\n",
    "df_loss = pd.DataFrame(data_loss)\n",
    "\n",
    "# Устанавливаем формат отображения чисел\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Выводим датафрейм\n",
    "print(df_loss.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Предсказание\n",
    "Используем обученные модели для предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(model, x):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(x).unsqueeze(0).unsqueeze(-1)\n",
    "        y_pred = model(x)\n",
    "    return y_pred.squeeze().numpy()\n",
    "\n",
    "# Пример предсказания\n",
    "x_test = X_test[0].squeeze().numpy()\n",
    "y_test = Y_test[0].numpy()\n",
    "\n",
    "y_pred_rnn = predict_sequence(rnn_model, x_test)\n",
    "y_pred_lstm = predict_sequence(lstm_model, x_test)\n",
    "y_pred_gru = predict_sequence(gru_model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём словарь с данными\n",
    "data = {\n",
    "    'True y': y_test,\n",
    "    'RNN Predicted y': y_pred_rnn,\n",
    "    'LSTM Predicted y': y_pred_lstm,\n",
    "    'GRU Predicted y': y_pred_gru\n",
    "}\n",
    "\n",
    "# Создаём датафрейм\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Преобразуем 'True y' в целые числа\n",
    "df['True y'] = df['True y'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict...\n",
      " True y  RNN Predicted y  LSTM Predicted y  GRU Predicted y\n",
      "      0            4.711             0.016           -0.128\n",
      "      4            4.213             4.087            4.018\n",
      "      6            4.245             5.806            6.462\n",
      "      6            4.440             5.794            6.066\n",
      "      9            4.783             8.701            9.024\n",
      "      0            4.080             0.077            0.055\n",
      "      8            4.525             7.959            7.804\n",
      "      6            4.657             6.012            5.930\n",
      "      1            4.423             0.962            0.979\n",
      "      7            4.399             7.068            7.048\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict...\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss... \n",
      "Модель  Test Loss\n",
      "   RNN      8.287\n",
      "  LSTM      0.006\n",
      "   GRU      0.003\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss... \")\n",
    "print(df_loss.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из таблицы  predict видно, что модель LSTM и GRU, показали более лучший результат вероятностей. Если посмотреть на Loss, то GRU выглядит немного лучше.   \n",
    "На мой взгляд, обе модели LSTM и GRU показали качественный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2 (дополнительное и необязательное)\n",
    "применить LSTM для решения лекционного практического [задания](https://colab.research.google.com/drive/1_rNrPHl6sYHNp-xo2G6I_SmRGTSSeICL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
