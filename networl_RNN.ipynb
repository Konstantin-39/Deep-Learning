{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPtrTPuSOcq_"
      },
      "source": [
        "### **Задание 1**   \n",
        "Обучим нейронную сеть решать шифр Цезаря\n",
        "\n",
        "*Что необходимо сделать:*\n",
        "\n",
        "1. Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)\n",
        "2. Сделать нейронную сеть\n",
        "3. Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)\n",
        "4. Проверить качество"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvnRnuM8OcrC"
      },
      "source": [
        "### **Задание 2**   \n",
        "\n",
        "1. Построить RNN-ячейку на основе полносвязных слоев\n",
        "2. Применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcPgreitOcrD"
      },
      "source": [
        "#### 1. Написать алгоритм шифра Цезаря"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRsJWSlJOcrD",
        "outputId": "2e35c6b7-7bcb-4d3c-adbf-af5313644fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# загрузим необходимые библиотеки\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import random\n",
        "import string\n",
        "\n",
        "# Определяем устройство (GPU или CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iQho-vDlOcrF"
      },
      "outputs": [],
      "source": [
        "# Параметры\n",
        "ALPHABET = string.ascii_lowercase + \" \"  # алфавит (буквы + пробел)\n",
        "CHAR_TO_INDEX = {char: idx for idx, char in enumerate(ALPHABET)}  # символ → индекс\n",
        "INDEX_TO_CHAR = {idx: char for char, idx in CHAR_TO_INDEX.items()}  # индекс → символ\n",
        "VOCAB_SIZE = len(ALPHABET)  # размер словаря\n",
        "MAX_LEN = 50  # максимальная длина фразы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VuB3ml0aOcrG"
      },
      "outputs": [],
      "source": [
        "# Функция для шифрования текста\n",
        "def caesar_cipher(text, shift):\n",
        "    result = []\n",
        "    for char in text:\n",
        "        if char in CHAR_TO_INDEX:\n",
        "            idx = (CHAR_TO_INDEX[char] + shift) % VOCAB_SIZE\n",
        "            result.append(INDEX_TO_CHAR[idx])\n",
        "        else:\n",
        "            result.append(char)  # если символ не в алфавите, оставляем как есть\n",
        "    return \"\".join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l-RBQI_6OcrG"
      },
      "outputs": [],
      "source": [
        "# Генерация данных\n",
        "def generate_data(num_samples):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        # Генерируем случайную фразу длиной от 10 до MAX_LEN символов\n",
        "        length = random.randint(10, MAX_LEN)\n",
        "        text = \"\".join(random.choices(ALPHABET, k=length))\n",
        "        shift = random.randint(1, 10)  # случайный сдвиг от 1 до 10\n",
        "        encrypted_text = caesar_cipher(text, shift)  # шифруем текст\n",
        "        data.append((encrypted_text, text, shift))  # сохраняем зашифрованный текст, исходный текст и сдвиг\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnKluCcqOcrH"
      },
      "source": [
        "#### 2. Построим нейронную сеть\n",
        "\n",
        "1. Разбьем данные на токены (у нас символы)\n",
        "2. Закодируем числами\n",
        "3. Превратим в эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tNyLOsYSOcrI"
      },
      "outputs": [],
      "source": [
        "# Преобразование текста в тензор\n",
        "def text_to_tensor(text, max_len):\n",
        "    tensor = torch.zeros(max_len, dtype=torch.long).to(device)  # перемещаем на устройство\n",
        "    for i, char in enumerate(text[:max_len]):\n",
        "        tensor[i] = CHAR_TO_INDEX.get(char, CHAR_TO_INDEX[\" \"])  # неизвестные символы → пробел\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LldhPnlBOcrI"
      },
      "outputs": [],
      "source": [
        "HIDDEN_SIZE = 256  # размер скрытого состояния\n",
        "EPOCHS = 30  # количество эпох\n",
        "BATCH_SIZE = 128  # размер батча\n",
        "LEARNING_RATE = 0.001  # learning rate\n",
        "DROPOUT = 0.2  # Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55V7FVgTOcrJ"
      },
      "source": [
        "#### 3. Обучим нейронную сеть RNN\n",
        "3 слоя:\n",
        "1. Embeding (30)\n",
        "2. RNN (hidden_dim=128)\n",
        "3. Полносвязный слой для предсказания буквы (28, то есть размер словаря)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OlPhMqj6OcrJ"
      },
      "outputs": [],
      "source": [
        "# Нейронная сеть с учетом сдвига\n",
        "class CaesarDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, dropout):\n",
        "        super(CaesarDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.shift_embedding = nn.Embedding(11, hidden_size)  # сдвиги от 0 до 10\n",
        "        self.rnn = nn.RNN(hidden_size * 2, hidden_size, batch_first=True, num_layers=2, dropout=dropout)  # вход: символы + сдвиг\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, shift):\n",
        "        char_emb = self.embedding(x)  # эмбеддинги символов\n",
        "        shift_emb = self.shift_embedding(shift).unsqueeze(1).expand(-1, x.size(1), -1)  # эмбеддинги сдвига\n",
        "        combined = torch.cat((char_emb, shift_emb), dim=2)  # объединяем символы и сдвиг\n",
        "        x, _ = self.rnn(combined)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IoeiyaBFOcrJ"
      },
      "outputs": [],
      "source": [
        "# Подготовка данных\n",
        "data = generate_data(20000)  # генерируем 20,000 примеров\n",
        "encrypted_texts, original_texts, shifts = zip(*data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0j-Xa-ekOcrK"
      },
      "outputs": [],
      "source": [
        "# Преобразуем тексты в тензоры\n",
        "X = torch.stack([text_to_tensor(text, MAX_LEN) for text in encrypted_texts]).to(device)  # перемещаем на устройство\n",
        "Y = torch.stack([text_to_tensor(text, MAX_LEN) for text in original_texts]).to(device)  # перемещаем на устройство\n",
        "shifts = torch.tensor(shifts, dtype=torch.long).to(device)  # преобразуем сдвиги в тензор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gZpJMhcDOcrK"
      },
      "outputs": [],
      "source": [
        "# Создаем модель, функцию потерь и оптимизатор\n",
        "model = CaesarDecoder(VOCAB_SIZE, HIDDEN_SIZE, DROPOUT).to(device)  # перемещаем модель на устройство\n",
        "criterion = nn.CrossEntropyLoss().to(device)  # перемещаем функцию потерь на устройство\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)  # используем Adam\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # добавляем scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLeUTS3nOcrK"
      },
      "source": [
        "Обучение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CPrw9VaOcrL",
        "outputId": "3c1ad915-85c9-47b6-f70f-5f532da84980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30, Loss: 0.7161, Accuracy: 0.8272\n",
            "Epoch 2/30, Loss: 0.0458, Accuracy: 0.9795\n",
            "Epoch 3/30, Loss: 0.0391, Accuracy: 0.9805\n",
            "Epoch 4/30, Loss: 0.0362, Accuracy: 0.9824\n",
            "Epoch 5/30, Loss: 0.0347, Accuracy: 0.9827\n",
            "Epoch 6/30, Loss: 0.0344, Accuracy: 0.9824\n",
            "Epoch 7/30, Loss: 0.0328, Accuracy: 0.9832\n",
            "Epoch 8/30, Loss: 0.0314, Accuracy: 0.9839\n",
            "Epoch 9/30, Loss: 0.0305, Accuracy: 0.9846\n",
            "Epoch 10/30, Loss: 0.0300, Accuracy: 0.9847\n",
            "Epoch 11/30, Loss: 0.0288, Accuracy: 0.9852\n",
            "Epoch 12/30, Loss: 0.0284, Accuracy: 0.9855\n",
            "Epoch 13/30, Loss: 0.0282, Accuracy: 0.9856\n",
            "Epoch 14/30, Loss: 0.0282, Accuracy: 0.9857\n",
            "Epoch 15/30, Loss: 0.0281, Accuracy: 0.9856\n",
            "Epoch 16/30, Loss: 0.0281, Accuracy: 0.9857\n",
            "Epoch 17/30, Loss: 0.0276, Accuracy: 0.9858\n",
            "Epoch 18/30, Loss: 0.0278, Accuracy: 0.9859\n",
            "Epoch 19/30, Loss: 0.0279, Accuracy: 0.9858\n",
            "Epoch 20/30, Loss: 0.0277, Accuracy: 0.9860\n",
            "Epoch 21/30, Loss: 0.0273, Accuracy: 0.9861\n",
            "Epoch 22/30, Loss: 0.0272, Accuracy: 0.9862\n",
            "Epoch 23/30, Loss: 0.0272, Accuracy: 0.9861\n",
            "Epoch 24/30, Loss: 0.0273, Accuracy: 0.9862\n",
            "Epoch 25/30, Loss: 0.0271, Accuracy: 0.9863\n",
            "Epoch 26/30, Loss: 0.0272, Accuracy: 0.9862\n",
            "Epoch 27/30, Loss: 0.0271, Accuracy: 0.9862\n",
            "Epoch 28/30, Loss: 0.0270, Accuracy: 0.9863\n",
            "Epoch 29/30, Loss: 0.0272, Accuracy: 0.9862\n",
            "Epoch 30/30, Loss: 0.0271, Accuracy: 0.9863\n"
          ]
        }
      ],
      "source": [
        "# Обучение модели\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0  # для подсчета правильных предсказаний\n",
        "    total_samples = 0  # для подсчета общего числа символов\n",
        "\n",
        "    for i in range(0, len(X), BATCH_SIZE):\n",
        "        # Берем батч\n",
        "        X_batch = X[i:i + BATCH_SIZE]\n",
        "        Y_batch = Y[i:i + BATCH_SIZE]\n",
        "        shift_batch = shifts[i:i + BATCH_SIZE]  # сдвиги для батча\n",
        "\n",
        "        # Обнуляем градиенты\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Прямой проход\n",
        "        outputs = model(X_batch, shift_batch)  # передаем сдвиг в модель\n",
        "        outputs = outputs.view(-1, VOCAB_SIZE)\n",
        "        Y_batch = Y_batch.view(-1)\n",
        "\n",
        "        # Вычисляем потери\n",
        "        loss = criterion(outputs, Y_batch)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Обратный проход и обновление весов\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Вычисляем accuracy\n",
        "        _, predicted = torch.max(outputs, dim=1)  # получаем предсказанные символы\n",
        "        total_correct += (predicted == Y_batch).sum().item()  # считаем правильные предсказания\n",
        "        total_samples += Y_batch.size(0)  # общее количество символов в батче\n",
        "\n",
        "    # Обновляем learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Выводим статистику\n",
        "    accuracy = total_correct / total_samples  # вычисляем accuracy\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss / (len(X) // BATCH_SIZE):.4f}, Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq85m8FwOcrL"
      },
      "source": [
        "#### 4. Проверим качество модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0n4iotRLOcrL"
      },
      "outputs": [],
      "source": [
        "# Проверка качества\n",
        "def decode_text(model, encrypted_text, shift):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Ограничиваем длину входного текста\n",
        "        input_length = len(encrypted_text)\n",
        "        tensor = text_to_tensor(encrypted_text, input_length).unsqueeze(0).to(device)  # перемещаем на устройство\n",
        "        shift_tensor = torch.tensor([shift], dtype=torch.long).to(device)  # преобразуем сдвиг в тензор\n",
        "        output = model(tensor, shift_tensor)\n",
        "        _, indices = torch.max(output, dim=2)\n",
        "        decoded_text = \"\".join([INDEX_TO_CHAR[idx.item()] for idx in indices[0][:input_length]])  # обрезаем до длины исходного текста\n",
        "    return decoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQxrVXj_OcrL",
        "outputId": "33a56100-df91-47df-d01e-27eff7483cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing the model on multiple examples:\n",
            "Original: hello world\n",
            "Shift: 7\n",
            "Encrypted: olssvgcvysk\n",
            "Decoded: hello world\n",
            "----------------------------------------\n",
            "Original: neural network\n",
            "Shift: 6\n",
            "Encrypted: tk xgrftkzbuxq\n",
            "Decoded: neural network\n",
            "----------------------------------------\n",
            "Original: caesar cipher\n",
            "Shift: 1\n",
            "Encrypted: dbftbsadjqifs\n",
            "Decoded: caesar cipher\n",
            "----------------------------------------\n",
            "Original: deep learning\n",
            "Shift: 4\n",
            "Encrypted: hiitdpievrmrk\n",
            "Decoded: deep learning\n",
            "----------------------------------------\n",
            "Original: machine learning\n",
            "Shift: 6\n",
            "Encrypted: sginotkfrkgxtotm\n",
            "Decoded: machine learning\n",
            "----------------------------------------\n",
            "Original: artificial intelligence\n",
            "Shift: 8\n",
            "Encrypted: izaqnqkqithqvamttqomvkm\n",
            "Decoded: artificial intelligence\n",
            "----------------------------------------\n",
            "Original: data science\n",
            "Shift: 7\n",
            "Encrypted: kh hgzjplujl\n",
            "Decoded: data science\n",
            "----------------------------------------\n",
            "Original: python programming\n",
            "Shift: 3\n",
            "Encrypted: sawkrqcsurjudpplqj\n",
            "Decoded: python programming\n",
            "----------------------------------------\n",
            "Original: pytorch framework\n",
            "Shift: 10\n",
            "Encrypted: zhcyamrjpakwofyau\n",
            "Decoded: pytorch framewoak\n",
            "----------------------------------------\n",
            "Original: encryption algorithms\n",
            "Shift: 8\n",
            "Encrypted: mvkzfxaqwvhitowzqapu \n",
            "Decoded: encryption algorithms\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Пример использования\n",
        "texts = [\n",
        "    \"hello world\", \"neural network\", \"caesar cipher\", \"deep learning\",\n",
        "    \"machine learning\", \"artificial intelligence\", \"data science\",\n",
        "    \"python programming\", \"pytorch framework\", \"encryption algorithms\"\n",
        "]\n",
        "\n",
        "print(\"Testing the model on multiple examples:\")\n",
        "for text in texts:\n",
        "    shift = random.randint(1, 10)  # случайный сдвиг от 1 до 10\n",
        "    encrypted_text = caesar_cipher(text, shift)\n",
        "    decoded_text = decode_text(model, encrypted_text, shift)\n",
        "    print(f\"Original: {text}\")\n",
        "    print(f\"Shift: {shift}\")\n",
        "    print(f\"Encrypted: {encrypted_text}\")\n",
        "    print(f\"Decoded: {decoded_text}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNHdOjvOcrM"
      },
      "source": [
        "### Задание 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG2W8NXjOcrM"
      },
      "source": [
        "#### 1. Построим RNN-ячейку на основе полносвязных слоев"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-QRPdM5OcrM",
        "outputId": "2232b1f4-7df5-42bd-9dcb-3dab7170e5b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-f4ab2aa3fa7b>:2: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/simpsons_script_lines.csv')\n"
          ]
        }
      ],
      "source": [
        "# Загрузка данных\n",
        "df = pd.read_csv('/content/simpsons_script_lines.csv')\n",
        "phrases = df['normalized_text'].dropna().tolist()  # используем столбец normalized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "j4Yf-_XiOcrM",
        "outputId": "27534362-1977-4346-8651-816a883b7964"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bd01f7b7-5dec-4e18-9bb7-4a7b9cd36ef4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>number</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>timestamp_in_ms</th>\n",
              "      <th>speaking_line</th>\n",
              "      <th>character_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>raw_location_text</th>\n",
              "      <th>spoken_words</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9549</td>\n",
              "      <td>32</td>\n",
              "      <td>209</td>\n",
              "      <td>Miss Hoover: No, actually, it was a little of ...</td>\n",
              "      <td>848000</td>\n",
              "      <td>True</td>\n",
              "      <td>464.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>No, actually, it was a little of both. Sometim...</td>\n",
              "      <td>no actually it was a little of both sometimes ...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9550</td>\n",
              "      <td>32</td>\n",
              "      <td>210</td>\n",
              "      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n",
              "      <td>856000</td>\n",
              "      <td>True</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>Where's Mr. Bergstrom?</td>\n",
              "      <td>wheres mr bergstrom</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9551</td>\n",
              "      <td>32</td>\n",
              "      <td>211</td>\n",
              "      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n",
              "      <td>856000</td>\n",
              "      <td>True</td>\n",
              "      <td>464.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
              "      <td>i dont know although id sure like to talk to h...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9552</td>\n",
              "      <td>32</td>\n",
              "      <td>212</td>\n",
              "      <td>Lisa Simpson: That life is worth living.</td>\n",
              "      <td>864000</td>\n",
              "      <td>True</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>That life is worth living.</td>\n",
              "      <td>that life is worth living</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9553</td>\n",
              "      <td>32</td>\n",
              "      <td>213</td>\n",
              "      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n",
              "      <td>864000</td>\n",
              "      <td>True</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Edna Krabappel-Flanders</td>\n",
              "      <td>Springfield Elementary School</td>\n",
              "      <td>The polls will be open from now until the end ...</td>\n",
              "      <td>the polls will be open from now until the end ...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd01f7b7-5dec-4e18-9bb7-4a7b9cd36ef4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd01f7b7-5dec-4e18-9bb7-4a7b9cd36ef4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd01f7b7-5dec-4e18-9bb7-4a7b9cd36ef4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54a45008-ec3b-462b-877b-18fbcd79fc38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54a45008-ec3b-462b-877b-18fbcd79fc38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54a45008-ec3b-462b-877b-18fbcd79fc38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     id  episode_id  number  \\\n",
              "0  9549          32     209   \n",
              "1  9550          32     210   \n",
              "2  9551          32     211   \n",
              "3  9552          32     212   \n",
              "4  9553          32     213   \n",
              "\n",
              "                                            raw_text timestamp_in_ms  \\\n",
              "0  Miss Hoover: No, actually, it was a little of ...          848000   \n",
              "1  Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n",
              "2  Miss Hoover: I don't know. Although I'd sure l...          856000   \n",
              "3           Lisa Simpson: That life is worth living.          864000   \n",
              "4  Edna Krabappel-Flanders: The polls will be ope...          864000   \n",
              "\n",
              "  speaking_line character_id  location_id       raw_character_text  \\\n",
              "0          True        464.0          3.0              Miss Hoover   \n",
              "1          True          9.0          3.0             Lisa Simpson   \n",
              "2          True        464.0          3.0              Miss Hoover   \n",
              "3          True          9.0          3.0             Lisa Simpson   \n",
              "4          True         40.0          3.0  Edna Krabappel-Flanders   \n",
              "\n",
              "               raw_location_text  \\\n",
              "0  Springfield Elementary School   \n",
              "1  Springfield Elementary School   \n",
              "2  Springfield Elementary School   \n",
              "3  Springfield Elementary School   \n",
              "4  Springfield Elementary School   \n",
              "\n",
              "                                        spoken_words  \\\n",
              "0  No, actually, it was a little of both. Sometim...   \n",
              "1                             Where's Mr. Bergstrom?   \n",
              "2  I don't know. Although I'd sure like to talk t...   \n",
              "3                         That life is worth living.   \n",
              "4  The polls will be open from now until the end ...   \n",
              "\n",
              "                                     normalized_text word_count  \n",
              "0  no actually it was a little of both sometimes ...         31  \n",
              "1                                wheres mr bergstrom          3  \n",
              "2  i dont know although id sure like to talk to h...         22  \n",
              "3                          that life is worth living          5  \n",
              "4  the polls will be open from now until the end ...         33  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qWJAcj52OcrN"
      },
      "outputs": [],
      "source": [
        "# Преобразуем тексты в список символов\n",
        "text = [[char for char in phrase] for phrase in phrases if isinstance(phrase, str)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PvDgv74wOcrN"
      },
      "outputs": [],
      "source": [
        "# Создаем тензор для хранения индексов символов\n",
        "X = torch.zeros((len(text), MAX_LEN), dtype=torch.long).to(device)  # перемещаем на устройство\n",
        "\n",
        "# Заполняем тензор индексами символов\n",
        "for i, phrase in enumerate(text):\n",
        "    for j, char in enumerate(phrase):\n",
        "        if j >= MAX_LEN:\n",
        "            break\n",
        "        X[i, j] = CHAR_TO_INDEX.get(char, CHAR_TO_INDEX[\" \"])  # неизвестные символы → пробел"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wfeLYilTOcrO"
      },
      "outputs": [],
      "source": [
        "# Кастомная RNN-ячейка на основе полносвязных слоев\n",
        "class CustomRNNCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(CustomRNNCell, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size, hidden_size)  # вход -> скрытое состояние\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)  # скрытое состояние -> скрытое состояние\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        hidden = torch.tanh(self.i2h(x) + self.h2h(hidden))  # обновляем скрытое состояние\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mvKLo7MaOcrO"
      },
      "outputs": [],
      "source": [
        "# Нейронная сеть с кастомной RNN-ячейкой\n",
        "class TextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, dropout):\n",
        "        super(TextGenerator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn_cell = CustomRNNCell(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros(x.size(0), self.hidden_size).to(device)  # инициализация скрытого состояния\n",
        "        x = self.embedding(x)\n",
        "        outputs = []\n",
        "        for i in range(x.size(1)):  # проходим по каждому символу в последовательности\n",
        "            hidden = self.rnn_cell(x[:, i, :], hidden)  # обновляем скрытое состояние\n",
        "            outputs.append(hidden)\n",
        "        outputs = torch.stack(outputs, dim=1)  # объединяем выходы\n",
        "        outputs = self.dropout(outputs)\n",
        "        outputs = self.fc(outputs)\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Go6RVZ0cOcrO"
      },
      "outputs": [],
      "source": [
        "# Подготовка данных\n",
        "X = X.to(device)\n",
        "Y = torch.roll(X, shifts=-1, dims=1).to(device)  # сдвигаем X на 1 влево для получения целевых символов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BDUshwlDOcrO"
      },
      "outputs": [],
      "source": [
        "# Создаем модель, функцию потерь и оптимизатор\n",
        "model = TextGenerator(VOCAB_SIZE, HIDDEN_SIZE, DROPOUT).to(device)  # перемещаем модель на устройство\n",
        "criterion = nn.CrossEntropyLoss().to(device)  # перемещаем функцию потерь на устройство\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)  # используем Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u2ew2CvOcrO",
        "outputId": "1ed6f44b-72bf-4c17-c34f-7cab3c8a6f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30, Loss: 1.2279\n",
            "Epoch 2/30, Loss: 1.2115\n",
            "Epoch 3/30, Loss: 1.1989\n",
            "Epoch 4/30, Loss: 1.1910\n",
            "Epoch 5/30, Loss: 1.1851\n",
            "Epoch 6/30, Loss: 1.1816\n",
            "Epoch 7/30, Loss: 1.1775\n",
            "Epoch 8/30, Loss: 1.1749\n",
            "Epoch 9/30, Loss: 1.1725\n",
            "Epoch 10/30, Loss: 1.1708\n",
            "Epoch 11/30, Loss: 1.1687\n",
            "Epoch 12/30, Loss: 1.1671\n",
            "Epoch 13/30, Loss: 1.1668\n",
            "Epoch 14/30, Loss: 1.1651\n",
            "Epoch 15/30, Loss: 1.1646\n",
            "Epoch 16/30, Loss: 1.1640\n",
            "Epoch 17/30, Loss: 1.1625\n",
            "Epoch 18/30, Loss: 1.1622\n",
            "Epoch 19/30, Loss: 1.1621\n",
            "Epoch 20/30, Loss: 1.1617\n",
            "Epoch 21/30, Loss: 1.1611\n",
            "Epoch 22/30, Loss: 1.1597\n",
            "Epoch 23/30, Loss: 1.1600\n",
            "Epoch 24/30, Loss: 1.1603\n",
            "Epoch 25/30, Loss: 1.1604\n",
            "Epoch 26/30, Loss: 1.1594\n",
            "Epoch 27/30, Loss: 1.1588\n",
            "Epoch 28/30, Loss: 1.1585\n",
            "Epoch 29/30, Loss: 1.1588\n",
            "Epoch 30/30, Loss: 1.1595\n"
          ]
        }
      ],
      "source": [
        "# Обучение модели\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0  # для подсчета правильных предсказаний\n",
        "    total_samples = 0  # для подсчета общего числа символов\n",
        "\n",
        "    for i in range(0, len(X), BATCH_SIZE):\n",
        "        # Берем батч\n",
        "        X_batch = X[i:i + BATCH_SIZE]\n",
        "        Y_batch = Y[i:i + BATCH_SIZE]\n",
        "\n",
        "        # Обнуляем градиенты\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Прямой проход\n",
        "        outputs, _ = model(X_batch)\n",
        "        outputs = outputs.view(-1, VOCAB_SIZE)\n",
        "        Y_batch = Y_batch.view(-1)\n",
        "\n",
        "        # Вычисляем потери\n",
        "        loss = criterion(outputs, Y_batch)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Обратный проход и обновление весов\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Вычисляем accuracy\n",
        "        _, predicted = torch.max(outputs, dim=1)  # получаем предсказанные символы\n",
        "        total_correct += (predicted == Y_batch).sum().item()  # считаем правильные предсказания\n",
        "        total_samples += Y_batch.size(0)  # общее количество символов в батче\n",
        "\n",
        "    # Выводим статистику\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss / (len(X) // BATCH_SIZE):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAKHyHQ9OcrP"
      },
      "source": [
        "#### 2. Применим построенную ячейку для генерации текста с выражениями героев сериала \"Симпсоны\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ecw41PgnOcrP"
      },
      "outputs": [],
      "source": [
        "# Генерация текста\n",
        "def generate_text(model, start_text, max_length=50):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Преобразуем начальный текст в тензор\n",
        "        input_tensor = text_to_tensor(start_text, len(start_text)).unsqueeze(0).to(device)\n",
        "        hidden = None\n",
        "        generated_text = list(start_text)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            output, hidden = model(input_tensor, hidden)\n",
        "            _, predicted = torch.max(output[:, -1, :], dim=1)\n",
        "            next_char = INDEX_TO_CHAR[predicted.item()]\n",
        "            generated_text.append(next_char)\n",
        "            input_tensor = text_to_tensor(next_char, 1).unsqueeze(0).to(device)\n",
        "\n",
        "        return \"\".join(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiVhA7XCOcrP",
        "outputId": "e4953b23-f1c3-4f87-e8f4-22ef338a325f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text: homer the see the show you the see the show you the see\n"
          ]
        }
      ],
      "source": [
        "# Пример генерации текста\n",
        "start_text = \"homer\"\n",
        "generated_text = generate_text(model, start_text, max_length=50)\n",
        "print(f\"Generated text: {generated_text}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
